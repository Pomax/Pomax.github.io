<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<atom:link href="http://pomax.github.io/gh-weblog-2/rss.xml" rel="self" type="application/rss+xml" />
<title>Pomax.github.io</title>
<description>My blog on github</description>
<link>http://pomax.github.io</link>
<lastBuildDate>Sat, 15 Apr 2023 19:17:28 GMT</lastBuildDate>
<pubDate>Sat, 15 Apr 2023 19:17:28 GMT</pubDate>
<ttl>1440</ttl>
<item>
<title>Leaving twitter</title>
<description>&lt;p&gt;In October of 2022, Elon Musk, a man who failed up harder than anyone else in history, decided to buy Twitter with the express intent to turn it into a completely different product. He laid off thousands of people, devalued the company by 50%, and started pushing through changes that not only changed the experience of the platform, but also made sure that you had no way of actually seeing the content you wanted, while at the same time pushing ads into every single stream presented to you.&lt;/p&gt;
&lt;p&gt;I signed up for Twitter back in 2009, and it's fun a (mostly) fun ride, but even when it wasn't, there were always two things preventing folks from leaving the platform: (1) it was rarely &lt;em&gt;that&lt;/em&gt; bad, and (2) there was no genuine alternative. &lt;/p&gt;
&lt;p&gt;Both those things changed in recent years. For several years now, Mastodon has been an alternative to Twitter, and with Elon's destruction of Twitter the number of both Mastodon users and Mastodon servers has exploded. It's now a perfectly fine alternative with plenty of folks to follow. No, they're not all on the same server, but it's not like you had problems sending emails to people who didn't use your email server before, and this is the same. Just follow them, irrespective of which server they happen to use. Done, you just need to know their "homepage", hardly a chore.&lt;/p&gt;
&lt;p&gt;So as Musk lands more and garbage features in a desperate attempt to short-term claw back money, I'm calling it quits. To prevent people from namesquatting, I'm keeping my twitter account, and I'm not deleting any old tweets, but I'll be using mastodon exclusively from now on. &lt;/p&gt;
&lt;p&gt;Find me over on &lt;a href="https://mastodon.social/@TheRealPomax"&gt;https://mastodon.social/@TheRealPomax&lt;/a&gt;&lt;/p&gt;
</description>
<category>Mastodon</category>
<category>Twitter</category>
<link>http://pomax.github.io/#gh-weblog-1681585670331</link>
<guid>http://pomax.github.io/#gh-weblog-1681585670331</guid>
<pubDate>Sat, 15 Apr 2023 19:07:50 GMT</pubDate>
</item>
<item>
<title> Getting elevation data out of DEM/DSM GeoTIFF files</title>
<description>&lt;p&gt;I'm working on a fun little side project implementing an autopilot in JavaScript to "drive" planes in Microsoft Flight Simulator 2020, and one of the things it needs is an altitude computer/terrain follow system. And in order to make that reasonably accurate, I figured I'd download the entire planet's elevation data in the form of the &lt;a href="https://www.eorc.jaxa.jp/ALOS/en/dataset/aw3d30/aw3d30_e.htm"&gt;ALOS Wolrd 3D (30m)&lt;/a&gt; dataset. This is around 450GB of DSM data, and takes the form of &lt;a href="http://geotiff.maptools.org/spec/geotiff2.html"&gt;GeoTiff&lt;/a&gt; files.&lt;/p&gt;
&lt;p&gt;Conventional GIS wisdom says that in order to work with that, you need to use &lt;a href="https://gdal.org/"&gt;GDAL&lt;/a&gt;, which has no Node bindings, but it has a Python API. And Python's not hard to use, but having to use two different programming languages is inconvenient. So after writing working python GDAL code, which takes 23 seconds to get the full file list of available tiles on my NAS, I figured I'd see if there was a Node library that worked with GDAL anyway.&lt;/p&gt;
&lt;p&gt;Turns out there is, or rather, there are. I ended up using &lt;a href="https://github.com/mmomtchev/node-gdal-async"&gt;gdal-async&lt;/a&gt;, which is a fork of &lt;a href="https://github.com/contra/node-gdal-next"&gt;https://github.com/contra/node-gdal-next&lt;/a&gt;, which is a fork of &lt;a href="https://github.com/naturalatlas/node-gdal"&gt;https://github.com/naturalatlas/node-gdal&lt;/a&gt;,  and reimplementing the logic on the Python side in Node yields a codebase that can index the same files, on the same NAS, in 7 seconds instead of 23. So that's weird, but better than before.&lt;/p&gt;
&lt;p&gt;I ended up writing out the file index to a 24000 line JSON file as a cache, hoping that'd be faster, and where it takes Python a bit to run through that, Node.js loads that instantly. &lt;em&gt;And&lt;/em&gt; parses it to a JS datastructure. The server's just up the moment I run &lt;code&gt;node server.js&lt;/code&gt; instead of spending a second or two starting up. &lt;/p&gt;
&lt;p&gt;But it gets better: why am I using GDAL at all if all I want is the elevations for GPS coordinates? Surely, GeoTIFF is not so complex that only giant GIS projects can make sense of them? And it turns out that, no, it's not. It's in fact near-trivial to write your own code for this provided you know a little bit of programming: GeoTIFF put all the information you need in the "fields" section of an IFD block (the kind of blocks a TIFF file is built up from), so we can just use &lt;a href="https://www.npmjs.com/package/tiff"&gt;a tiff parser&lt;/a&gt; to get those fields, and then look up what values we need in order to map GPS coordinates to TIFF pixel indices (See &lt;a href="https://stackoverflow.com/a/75647596/740553"&gt;https://stackoverflow.com/a/75647596/740553&lt;/a&gt; for an overly detailed explanation on the how!)&lt;/p&gt;
&lt;p&gt;So, how much code is it when we implement the entire thing, bar the TIFF parser, ourselves? This much code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-javascript"&gt;import { existsSync, copyFileSync, readFileSync, writeFileSync } from "fs";
import { basename, join } from "path";
import tiff from "tiff";
const { floor, ceil } = Math;

const __dirname = url.fileURLToPath(new URL(".", import.meta.url));
const INDEX_FILE = join(__dirname, `alos-index.json`);
const CACHE_DIR = join(__dirname, `cache`);
const ALOS_VOID_VALUE = -9999;

class ALOSTile {
  constructor(tilePath) {
    this.tilePath = tilePath;
    // copy to cache dir for faster loading
    const filename = join(`.`, CACHE_DIR, basename(tilePath));
    if (!existsSync(filename)) copyFileSync(tilePath, filename);
    this.init(filename);
  }

  init(filename) {
    const file = readFileSync(filename);
    const image = tiff.decode(file.buffer);
    const block = (this.block = image[0]);
    const fields = block.fields;
    let [sx, sy, sz] = fields.get(33550);
    let [px, py, k, gx, gy, gz] = fields.get(33922);
    sy = -sy;
    this.reverse = [-gx / sx, 1 / sx, 0, -gy / sy, 0, 1 / sy];
    this.pixels = block.data;
  }

  lookup(lat, long) {
    const { reverse: T, block } = this;
    const x = T[0] + T[1] * long + T[2] * lat;
    const y = T[3] + T[4] * long + T[5] * lat;
    const pos = (x | 0) + (y | 0) * block.width;
    const value = this.pixels[pos];
    return value ?? ALOS_VOID_VALUE;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There, that's the entire code &lt;em&gt;plus convenience wrapper&lt;/em&gt; to do an elevation lookup in a GeoTIFF tile. No GDAL, no Python, heck we don't even need to care about which programming language we're using as long as it has a TIFF parser it can use. The rest is just absolutely basic programming.&lt;/p&gt;
</description>
<category>Node</category>
<category>GIS</category>
<category>GDAL</category>
<category>MSFS</category>
<category>MSFS 2020</category>
<category>Elevation</category>
<category>DEM</category>
<category>DSM</category>
<link>http://pomax.github.io/#gh-weblog-1678206967957</link>
<guid>http://pomax.github.io/#gh-weblog-1678206967957</guid>
<pubDate>Tue, 07 Mar 2023 16:36:07 GMT</pubDate>
</item>
<item>
<title>MacOS and external SSDs</title>
<description>&lt;p&gt;Ever had your external SSD refuse to remount when you plug it into MacOS because it's an idiotic OS and remembers you didn't properly ejected it?&lt;/p&gt;
&lt;p&gt;First, kill &lt;code&gt;fsck&lt;/code&gt; (the "file system consistency check" with the dumbest command name) because it's ruining the party right now:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ps aux | grep fsck
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Find the process id and &lt;code&gt;sudo kill -9 thatid&lt;/code&gt; because goddamnit, fsck, stop ruining the party. It's even going to do a fake out, because there's probably two pids, and only one of them is real. The other's a zombie process.&lt;/p&gt;
&lt;p&gt;With the main one killed, we can remount the drive:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ diskutils mount /Volumes/disk3s2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or whatever your disk volume is according to Disk Utility.&lt;/p&gt;
</description>
<category>MacOS</category>
<category>SSD</category>
<category>fsck</category>
<link>http://pomax.github.io/#gh-weblog-1676434414432</link>
<guid>http://pomax.github.io/#gh-weblog-1676434414432</guid>
<pubDate>Wed, 15 Feb 2023 04:13:34 GMT</pubDate>
</item>
<item>
<title> Adding a physical drive to a VMware Workstation VM</title>
<description>&lt;p&gt;If VMWare complains that it has insufficient rights to use a physical drive with adding a hard disk in the VM settings: open computer management with admin rights, then look for that drive in the list. If it has a drive letter: remove the drive letter. &lt;/p&gt;
&lt;p&gt;Remember: adding a physical drive means literally giving it to the guest OS, not "sharing it between the host and the guest", so remove its drive letter in computer management to &lt;em&gt;guarantee&lt;/em&gt; that your host's Windows can't use it. Once done, you can add it to your VM without any problems.&lt;/p&gt;
&lt;p&gt;And if you need to &lt;em&gt;share&lt;/em&gt; drives, just use network sharing. That's what it's for.&lt;/p&gt;
</description>
<category>VMware</category>
<category>Workstation</category>
<category>drive</category>
<category>errors</category>
<link>http://pomax.github.io/#gh-weblog-1672175588471</link>
<guid>http://pomax.github.io/#gh-weblog-1672175588471</guid>
<pubDate>Tue, 27 Dec 2022 21:13:08 GMT</pubDate>
</item>
<item>
<title> Structs in Python</title>
<description>&lt;p&gt;Python does not have syntax for writing C structs, or things that act like them, but thankfully you can write a class decorator that adds something that feels like it should have been in the language from day one.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import copy


def struct(struct_class):
    # extract the struct members
    member_names = []
    member_values = []
    for attr_name in dir(struct_class):
        if not attr_name.startswith('_'):
            value = getattr(struct_class, attr_name)
            if not callable(value):
                member_names.append(attr_name)
                member_values.append(value)

    # create a new init
    def struct_init(self, *args, **kwargs):
        i = 0  # we really don't need enumerate() here...
        for value in args:
            name = member_names[i]
            default_value = member_values[i]
            setattr(self, name, value if value is not None else default_value)
            i += 1  # ...we just need to inc an int
        for key, value in kwargs.items():
            if key in member_names:
                i = member_names.index(key)
                default_value = member_values[i]
                setattr(self, key, value if value is not None else default_value)
        # fall through  to the struct constructor.
        if hasattr(self.__class__, 'constructor'):
            self.constructor(**kwargs)

    # A struct can be iterated over, yielding and ordered list
    # based on member names defined in the struct class.
    def member_iter(self):
        return [copy.deepcopy(getattr(self, name)) for name in member_names].__iter__()

    # Structs do not allow shallow copying. All copies are a deep copies.
    def deep_copy(self):
        return copy.deepcopy(self)

    # rebind and return
    struct_class.__init__ = struct_init
    struct_class.__iter__ = member_iter
    struct_class.__copy__ = deep_copy
    return struct_class
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this, we can write code with nice Struct-likes:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from as_struct import struct

@struct
class Orientation():
    pitch = 0
    roll = 0
    yaw = 0

@struct
class Trim():
    elevator = 0
    aileron = 0
    rudder = 0

class Brrrrrr():
    def __init__(self):
        self.description = "I'm a plane!"
        self.orientation = Orientation()
        self.trim = Trim()

    def trim(self, e=0, a=0, r=0):
        self.trim.elevator += e
        self.trim.aileron += a
        self.trim.rudder += r
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Done.&lt;/p&gt;
</description>
<category>Python</category>
<category>struct</category>
<category>decorator</category>
<link>http://pomax.github.io/#gh-weblog-1671995243640</link>
<guid>http://pomax.github.io/#gh-weblog-1671995243640</guid>
<pubDate>Sun, 25 Dec 2022 19:07:23 GMT</pubDate>
</item>
<item>
<title> React is just JavaScript</title>
<description>&lt;p&gt;React has had a fairly profound effect on the web, whether you like React or not, and whether you like the effect it had or not. However, the one thing it's done that's somewhat puzzling is make people think that React is its own thing, rather than just JS. Things that are trivial become colossal tasks and implementations because folks try to do them "in React". Anything that isn't DOM-update related needs a React solution, instead of using the JS APIs that are right there for you to use. So let's talk about a few.&lt;/p&gt;
&lt;h2 id="how-do-i-tell-component-x-about-an-update-in-component-y-"&gt;How do I tell component X about an update in component Y?&lt;/h2&gt;
&lt;p&gt;Imagine this: you wrote a React app that has a status and a whole bunch of different content, and you need to make sure your status bar reflects whatever is active right now. So you add a ref to your status bar, communicate that up to the parent &lt;code&gt;App&lt;/code&gt;, which can then pass down a handler to every component until it makes it down into your components that can be active.&lt;/p&gt;
&lt;p&gt;Or, you go "oh right, wait, I'm in a browser" and you just use events: your active component just fires-and-forgets a &lt;code&gt;document.dispatchEvent(new CustomEvent(`status:active`, { detail: ... }))&lt;/code&gt; and your status bar registers a listener for that event when it mounts. We are done: nothing needs to run up and down an entire virtual DOM tree. And because this is basically just utility functionality, we write it as its own function that any component that needs to update the status bar can use, which we can import &lt;em&gt;from&lt;/em&gt; the Status bar:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// The only code that cares about this event name is the code
// in this file, so we capture it as a constant and nothing will
// ever need to care about what it is.
const STATUS_EVENT_NAME = `app:status:update`;

// yes, this is when you want a class, not a functional component
export class StatusBar extends React.Component {
  static getDefaultState() {
    return { statusMessage: `` };
  }
  constructor(props) {
    super(props);
    this.state = StatusBar.getDefaultState();
  }
  reset() {
    this.setState(StatusBar.getDefaultState());
  }
  componentDidMount() {
    document.addEventListener(STATUS_EVENT_NAME, evt =&amp;gt; {
      const { statusMessage } = evt.detail;
      this.setState({ statusMessage });
    );
  }
  render() {
    return &amp;lt;footer className=""&amp;gt;{ this.state.statusMessage }&amp;lt;/footer&amp;gt;
  }
}

// And a nice function that other components with a status bar text can import and use:
export function updateStatusBar(msg) {
  const evt = new CustomEvent(STATUS_EVENT_NAME, { detail: msg });
  document.dispatchEvent(evt);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And look at that: no refs, no property forwards, or even crazier "sending the handler up to the parent once it's available" nonsense. You want some content to update the status bar? Just do that:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import { updateStatusBar } from "./StatusBar.js";

export const SomeContent = function(props) {
  useEffect(() =&amp;gt; updateStatusBar(props.toolTip), props.toolTip);
  return &amp;lt;......&amp;gt;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Heck, this even works when there is no status bar component on the page. The events just get thrown away if there are no listeners for it, and everything works perfectly fine.&lt;/p&gt;
&lt;h2 id="how-do-i-synchronize-data-across-components-"&gt;How do I synchronize data across components?&lt;/h2&gt;
&lt;p&gt;Well, you could use Redux and learn a complex new technology, or you could just use JS, because anything running client-side is running within the same context, and imports are cached, so imports are shared by default. Want to see something that looks like it shouldn't be this simple?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export const dataPool = {};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Boom, done. Anything with &lt;code&gt;import { dataPool } from "datapool.js";&lt;/code&gt; will now be sharing the same object. It's how JS works by design, we get this for free. And you can even get fancy without bolting on a data syncing framework until you absolutely need it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const pool = {};
export const dataPool = {
  register: listener =&amp;gt; listeners.push(listener);
  unregister: listener =&amp;gt; {
    const pos = listeners.indexOf(listener);
    if (pos &amp;gt; -1) listeners.splice(pos, 1);
  },
  getValue: (name) =&amp;gt; pool[name],
  setValue: (name, value) =&amp;gt; {
    pool.name = value;
    for (let listener of listeners) listener.poolUpdated?(name, value);
  }
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And now you have a synced data pool that uses a pub/sub model for data updates in less than 15 lines of code. &lt;/p&gt;
&lt;h3 id="but-this-doesn-t-persist-"&gt;But this doesn't persist!&lt;/h3&gt;
&lt;p&gt;So save the data to &lt;code&gt;localStorage&lt;/code&gt;, that's what it's for:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const dataKey = `app:dataPool`;
const pool = JSON.parse(localStorage.getItem(dataKey) ?? `{}`);

export const dataPool = {
  register: listener =&amp;gt; listeners.push(listener);
  unregister: listener =&amp;gt; {
    const pos = listeners.indexOf(listener);
    if (pos &amp;gt; -1) listeners.splice(pos, 1);
  },
  getValue: (name) =&amp;gt; pool[name],
  setValue: (name, value) =&amp;gt; {
    pool.name = value;
    localStorage.setItem(dataKey, JSON.stringify(pool));
    for (let listener of listeners) listener.poolUpdated?(name, value);
  }
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Done. And now you have an excellent signal for when it's time to start thinking about more complex solutions, because &lt;code&gt;localStorage&lt;/code&gt; has limited space available. If you're syncing more than a few MB across lots of components, it's probably time to rethink your app architecture.&lt;/p&gt;
&lt;h2 id="i-want-to-close-my-modal-component-when-someone-clicks-or-taps-outside-of-it"&gt;I want to close my modal component when someone clicks or taps outside of it&lt;/h2&gt;
&lt;p&gt;This one's close to my heart because I originally wrote react-onclickoutside almost a decade ago now because back in Þe olden times JS was missing a &lt;em&gt;ton&lt;/em&gt; of features that modern JS has. Time has moved on, JS got updated a lot since, and so in modern JS we just.... don't need it anymore. Instead you can make this work with just a few lines of JS:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import { setupOutsideClickListener } from "./somewhere";

export const Menu = (props) =&amp;gt; {
  const menuRef = useRef(null);

  // let's assume we're smart and have a const function for toggling
  // visibility of this component, used by whatever other logic needs
  // to control visibility
  const toggle = () =&amp;gt; { ... }

  // set up the event listeners, using `[]` as dependency list so it only runs once.
  useEffect(() =&amp;gt; setupOutsideClickListener(menuRef, toggle), []);

  return (
    &amp;lt;dialog ref={menuRef} ... &amp;gt;
      &amp;lt;span className="close-icon" onClick={toggle}&amp;gt;X&amp;lt;/span&amp;gt;
        ...
    &amp;lt;/dialog
  );
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And here's our plain JavaScript:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export function setupOutsideClickListener(owner, toggle) {
  // always remember that if you have "click" handling, you better have a "touchstart", too!
  for (let type of [`click`, `touchstart`]) {
     document.addEventListener(type, ({ target }) =&amp;gt; {
        // if this dialog is not on the page, or the events occur anywhere inside our dialog, we ignore the events.
        if (owner.current?.contains(target)) return;
        // if the dialog is on the page and the events are outside of it, toggle its visibility.
        toggle();
      });
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="and-so-much-more"&gt;And so much more&lt;/h2&gt;
&lt;p&gt;Unless you're already a seasoned programmer, you're almost certainly writing way too much code to do what you need, simply because you've been focusing on React too much, and not spending some time with plain JS to understand what this language that you're using can actually do. Once you've spent some time with React, the best thing you can do for yourself is putting React down, and reading up on modern JS on the web - what it can do, what syntax it uses for that, and how a lot of that can replace what you've used &lt;em&gt;a lot&lt;/em&gt; of code for with surprisingly little code.&lt;/p&gt;
&lt;p&gt;Should you never use Redux? Or HoCs? Or anything else that's complex but full featured and everyone seems to be using? No of course not, but you should know &lt;em&gt;why&lt;/em&gt; you're using them, because they solve specific problems, and those are almost certainly not your problems. &lt;em&gt;Yet&lt;/em&gt;&lt;/p&gt;
</description>
<category>React</category>
<category>JavaScript</category>
<link>http://pomax.github.io/#gh-weblog-1657467300033</link>
<guid>http://pomax.github.io/#gh-weblog-1657467300033</guid>
<pubDate>Sun, 10 Jul 2022 15:35:00 GMT</pubDate>
</item>
<item>
<title> Cleaning up your Django migrations</title>
<description>&lt;p&gt;We use &lt;a href="https://wagtail.org/"&gt;Wagtail&lt;/a&gt;, a Django-based CMS, at the Mozilla Foundation to host &lt;a href="https://foundation.mozilla.org"&gt;https://foundation.mozilla.org&lt;/a&gt;, as well as &lt;a href="http://donate.mozilla.org"&gt;http://donate.mozilla.org&lt;/a&gt;, and as nice as Django is, it is pretty terrible at migration and app management. The official stance is "you shouldn't worry about how many migrations you have", and for a base Django installation, that might very well be true.&lt;/p&gt;
&lt;p&gt;For Wagtail installations, it very much isn't. Thanks to Wagtail's &lt;a href="https://docs.wagtail.org/en/stable/topics/streamfield.html"&gt;streamfield&lt;/a&gt; concept, which models free-form page body content "out of band" (using a single huge JSON string for each stream, rather than linked table data) you can end up with migrations where your code change may have been a short string update, but the migration for that updates the &lt;em&gt;entire&lt;/em&gt; streamfield definition JSON. A four letter change in your code can easily lead to a 12kb change in a migration field. Times every model that uses that same streamfield definition. 50kb+ migrations for tiny code changes are not unusual.&lt;/p&gt;
&lt;p&gt;So, when you use Wagtail you will almost certain run into the need to squash your migrations much sooner than you ever would if you just used plain Django, and we've had to do this enough times that it's really worth just writing down how to properly do this. So here's a checklist for you to run through:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use &lt;code&gt;squashmigration&lt;/code&gt; to first extremely-poorly-consolidate all your wagtail app's migrations: &lt;code&gt;python manage.py squashmigrations yourappname 1234&lt;/code&gt; (where 1234 is your most recent migration number). This will create a new &lt;code&gt;0001&lt;/code&gt; migration that is almost certainly not going to work without further editing because squashing does not automatically copy over any of your "run this during a migration" code. So we'll need to create a new migration file for that:&lt;/li&gt;
&lt;li&gt;Create a new migration file 0002 with a dependency on the new 0001, exclusively for data bootstrapping. Note that you do &lt;em&gt;not&lt;/em&gt; need any of the code that migrated data "between migrations": when squashing your migrations, all your model definitions and data are already up to date with respect to your current code, meaning that none of the migration functions that you had to run in the past to uplift older data to a newer form is relevant anymore. However, migration functions that &lt;em&gt;create&lt;/em&gt; data should all be put in your new 0002 migration. With, of course, the code updated to do what it's supposed to do given your &lt;em&gt;current&lt;/em&gt; code.  And of course, remember to remove all the &lt;code&gt;runPython&lt;/code&gt; instructions from the new 0001 migration&lt;/li&gt;
&lt;li&gt;After testing (of course), push these changes all the way through to production. &lt;/li&gt;
&lt;li&gt;We can now remove the old migrations: delete everything except the new 0001 and 0002, and make sure to update 0001 so that it no longer claims that it &lt;code&gt;replaces = ...&lt;/code&gt;, as those migration files will no longer exist.&lt;/li&gt;
&lt;li&gt;After testing (of course), again push these changes all the way through to production. &lt;/li&gt;
&lt;li&gt;We can now perform the part that we wanted from the start: move the newly created &lt;code&gt;0001&lt;/code&gt; and &lt;code&gt;0002&lt;/code&gt; migration files to a temp dir so that the &lt;code&gt;migrations&lt;/code&gt; dir is empty, and run &lt;code&gt;python manage.py makemigrations&lt;/code&gt; to create &lt;em&gt;completely new, fresh, clean, model definitions&lt;/em&gt;. Django is pretty terrible at migration optimization (which isn't its fault: that's a hard problem), and this step basically goes "okay, we know the model definitions are a single migration, so a completely new migration will lead to the same model definitions getting set up". Except without needing to optimize anything: you're quite likely to end up with a migration that is 10x smaller than the original squashed migration Django created.&lt;/li&gt;
&lt;li&gt;Make sure this newest 0001 migration has some name that is unique to when you're doing the work. E.g. &lt;code&gt;0001_2022_02_24_reset_models.py&lt;/code&gt;, and copy the original squash migration &lt;code&gt;0001&lt;/code&gt; and data bootstrap &lt;code&gt;0002&lt;/code&gt; that we moved to a temp dir back into the &lt;code&gt;migrations&lt;/code&gt; dir. Update the super clean migration so that it has a &lt;code&gt;replaces = ...&lt;/code&gt;  list, and have that list be the squashed 0001 and data bootstrap 0002 names.&lt;/li&gt;
&lt;li&gt;Copy the 0002 data bootstrap migration as a new 0002 file with the same kind of name as our super clean migration, e.g. &lt;code&gt;0002_2022_02_24_reset_data_bootstrap.py&lt;/code&gt; and update its &lt;code&gt;dependencies&lt;/code&gt; field to point to &lt;code&gt;0001_2022_02_24_reset_models&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;After testing (of course), we push these changes all the way through to production for a third time. We are not done yet.&lt;/li&gt;
&lt;li&gt;We can now delete the original squash migration and its data bootstrap migration, and remove the &lt;code&gt;replaces&lt;/code&gt; field from our super clean 0001 migration.&lt;/li&gt;
&lt;li&gt;After testing (yet again), we push these changes all the way through to production for the last time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Congratulations, you probably just cut your &lt;code&gt;python manage.py migrate&lt;/code&gt; runtime in half, if not more. &lt;/p&gt;
&lt;p&gt;But we're not done, because Django doesn't actually &lt;em&gt;know&lt;/em&gt; what we've done: its migration table still contains all the old migration information despite those files no longer existing, so we're going to have to go into the DB and update that part, too.  First off, connect to your production database, and run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT FROM django_migrations WHERE app = 'your_app_name';
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will show you all the migrations the django has ever see for your app. All but two of those are completely irrelevant now, so we're going to remove them. Take note of the &lt;code&gt;id&lt;/code&gt; for the new clean migration and its data bootstrap migration, and then run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; DELETE FROM django_migrations WHERE app = 'your_app_name' AND id &amp;lt; 1234567;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Where that &lt;code&gt;1234567&lt;/code&gt; is the lower of the two id numbers for your clean migrations.&lt;/p&gt;
&lt;p&gt;However, remember to &lt;strong&gt;always have database backups&lt;/strong&gt; before you do something like this. &lt;/p&gt;
&lt;p&gt;Also note, that this &lt;strong&gt;will cause problems&lt;/strong&gt; if you have multiple apps that have migration cross dependencies to your just-cleaned-up app. You will need to run this clean-squash procedure for &lt;em&gt;every&lt;/em&gt; app with dependencies on any of the apps you're cleaning this way, before you can clean up the &lt;code&gt;django_migrations&lt;/code&gt; table.&lt;/p&gt;
&lt;p&gt;And yeah: it's absolutely crazy that Django's been around for over fifteen years, but no one's really bothered to actually make this part easy. And don't even get me started on renaming a Django app. Heaven forbid you'd ever want to do that.&lt;/p&gt;
</description>

<link>http://pomax.github.io/#gh-weblog-1645994687853</link>
<guid>http://pomax.github.io/#gh-weblog-1645994687853</guid>
<pubDate>Sun, 27 Feb 2022 20:44:47 GMT</pubDate>
</item>
<item>
<title> Setting up "lots of HTTPS servers" with Node </title>
<description>&lt;p&gt;I'm working on a &lt;code&gt;server&lt;/code&gt; ⇆ &lt;code&gt;client&lt;/code&gt; ⇆ &lt;code&gt;browser-as-thin-client&lt;/code&gt; project where there is a single server, running an HTTPS and WS server process, with clients that first connect to the web server "Front door" before being sent on to their own dedicated websocket URL. These clients are just "computer programs" that someone can attach to with their browser if they need a user interface into the client, and so each client also runs their own little websocket server to allow for that.&lt;/p&gt;
&lt;p&gt;At some point, the idea is of course that the server runs on one machine, and clients run on however-many secondary machines, but for testing purposes that makes no sense: the server and clients all run on the same hardware.&lt;/p&gt;
&lt;p&gt;Which means I needed to set up HTTPs/SSL in a way that works for all these things, and thankfully it turns out that Node.js allows you to do this pretty easily. It even has &lt;a href="https://nodejs.org/api/https.html#httpscreateserveroptions-requestlistener"&gt;example code for this&lt;/a&gt; on the API pages for the &lt;code&gt;https&lt;/code&gt; module, which can be used in combination with a Let's Encrypt &lt;a href=""&gt;certbot&lt;/a&gt; key and certificate, and some env vars to regulate whether to use https or not:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import http from "http";
import https from "https";

const { USE_HTTPS, DOMAIN_NAME, PORT } = process.env;
const useHTTPS = USE_HTTPS === `true`;
const protocol = useHTTPS ? `https` : `http`;
const domain = DOMAIN_NAME || `localhost`;
const port = parseInt(PORT) || 8000;

const httpsOptions = {};

if (useHTTPS) {
  const certDir = `/etc/letsencrypt/live`;
  httpsOptions.key = fs.readFileSync(`${certDir}/${domain}/privkey.pem`);
  httpsOptions.cert = fs.readFileSync(`${certDir}/${domain}/fullchain.pem`);
}

function routHandlers(request, response) { 
  // ...
}

const namespace = (useHTTPS ? https : http);
const server = namespace.createServer(useHTTPS ? httpsOptions : undefined, routHandlers);

server.listen(port, () =&amp;gt; {
  console.log(`Server is listening on ${protocl}//${domain}:${port}`);
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then you just make sure every single server uses this approach.&lt;/p&gt;
</description>
<category>Node</category>
<category>HTTPS</category>
<category>server</category>
<link>http://pomax.github.io/#gh-weblog-1638815860591</link>
<guid>http://pomax.github.io/#gh-weblog-1638815860591</guid>
<pubDate>Mon, 06 Dec 2021 18:37:40 GMT</pubDate>
</item>
<item>
<title> If your software still relies on Python 2.7, your software is bad and you should feel bad.</title>
<description>&lt;p&gt;If that statement made you think you should tell me I'm wrong, then allow me to elaborate, because I tweeted this a while back and got some really weird responses that demonstrate &lt;em&gt;many&lt;/em&gt; folks don't understand what's wrong here, and that in itself is something worth fixing.&lt;/p&gt;
&lt;p&gt;Let's start with a bit of tech debt: you need to write a program, which language do you use? Cool, good choice, love it, totally the right call, so: what's your major version upgrade plan? Because the title statement isn't just about Python 2.7, Python 2.7 is just the latest example in a long and never-ending series of programming language versions that either have, are in the process of, or will become, obsolete and almost guaranteed security liabilities.&lt;/p&gt;
&lt;p&gt;For example, let's look at some statements that are exactly the same as the title, but that almost no one's going to get upset about:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If your software still relies on PHP 4 in 2021, your software is bad and you should feel bad.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I mean... obviously. If you're still writing new PHP 4 code, or you're refusing to uplift software that was originally written in PHP 4, instead just keeping on developing it in PHP 4, now you're just an intentional bad actor. The only way people can run your code is by installing software that we, which includes you, &lt;em&gt;know&lt;/em&gt; is a giant security exploit.&lt;/p&gt;
&lt;p&gt;Of course there will be code that was originally written for PHP 4 that did something incredibly useful back in the early 2000's, but no amount of utility can justify installing PHP 4 in the early 2020's.&lt;/p&gt;
&lt;p&gt;How about another one?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If your software still relies on Node 0.10 in 2021, your software is bad and you should feel bad.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I mean... have you looked at the list of CVEs for Node 0.10?  If you're still writing Node 0.10 code, or you're refusing to uplift software that was originally written in Node 0.10, instead just keeping on developing it in Node 0.10, then yeah, your software is bad and you should absolutely feel bad. If you're still working on it, why the hell are you not targeting the older of the two LTS versions of Node?&lt;/p&gt;
&lt;p&gt;Let's do one more.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If your software still relies on Java 1.4 in 2021, your software is bad and you should feel bad.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You get the point by now. Sure, there is code that got &lt;em&gt;released when Java 1.4 was current&lt;/em&gt; and did great things but if that code is still being maintained or worked on (not, "if that code is still being used", but if that code is still actively maintained, and has new releases pushed out, requiring Java 1.4) then that code should have been uplifted &lt;em&gt;several times&lt;/em&gt; over the last two decades.&lt;/p&gt;
&lt;h2 id="so-why-is-python-such-a-touchy-subject-"&gt;So why is Python such a touchy subject?&lt;/h2&gt;
&lt;p&gt;A lot of people are locked into it, whether they want to or not. And most don't want to.&lt;/p&gt;
&lt;p&gt;That's not their fault. A lot of software was originally written in 2.7, and again that's fine. But, a lot of companies still haven't uplifted their 2.7 code to v3 now that 2.7 has been dead for over a year, and that &lt;em&gt;&lt;strong&gt;is&lt;/strong&gt;&lt;/em&gt; their fault, and that &lt;em&gt;&lt;strong&gt;is&lt;/strong&gt;&lt;/em&gt; something they need to feel bad about, and address.&lt;/p&gt;
&lt;p&gt;How we got here is easy: Python 2.7 was around for a very, &lt;em&gt;very&lt;/em&gt; long time. Much too long, in fact, and for the longest of that long time, there wasn't even an end-of-life date for it. During the lifetime of 2.7, the new Python 3.0 got released. And then 3.1 got released as well... and then 3.2... and 3.3.... and 3.4... and 3.5... and 3.6... and 3.7... and 3.8... and 3.9... For an entire &lt;em&gt;decade&lt;/em&gt; of 3.x updates, 2.7 was just as viable a choice, despite being objectively worse in pretty much every way. So thanks to the fact that there was already a ton of 2.7 code being used when 3.0 came out, making people prefer "the old version" because you already needed to have 2.7 installed for the majority of the python code you needed anyway, and installing 3.x on the same machine was actually a royal pain in the backside, people kept developing new codebases in 2.7 and that was unfortunate and definitely a vicious cycle, but entirely understandable.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/python/devguide/pull/344"&gt;That changed in 2018&lt;/a&gt;, when a real end-of-life date for 2.7 was decided: as of January 1st 2020, python 2.7 would be dead. As in: properly dead. The same kind dead as PHP 4, or Node 0.10, or Java 1.4: any security hole, any exploit, any vulnerability that 2.7 still had is forever part of 2.7, because 2.7 has reached end-of-life. In 2020, we said goodbye to Python 2.7 - it was a glorious run, but it had to go, and it's good that it's gone. Long live Python 3.x, but with EOL dates for each version. Hurray!&lt;/p&gt;
&lt;p&gt;Now, practically, 2.7 didn't &lt;em&gt;actually&lt;/em&gt; die until April 2020, but throughout 2018 and 2019, people knew 2.7 would be gone soon, but the Python folks are &lt;em&gt;good people&lt;/em&gt;, and they actually created tools to help everyone uplift their code from v2 to v3. The &lt;a href="https://docs.python.org/3/library/2to3.html"&gt;2to3&lt;/a&gt; package is fantastic, and for a great many people, it's all they need. &lt;/p&gt;
&lt;p&gt;Now it's April 2021, and we reach the original premise:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If your software still relies on Python 2.7, your software is bad and you should feel bad.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note what this &lt;em&gt;doesn't&lt;/em&gt; say: it doesn't say that all Python 2.7 software ever written is bad, Python 2.7 code written in 2004 that does a thing no other code does had a damn good reason to exist, but it has zero reason to &lt;em&gt;still be maintained as a 2.7 code base&lt;/em&gt; because 2.7 is gone. Make your peace with that and move to 3.x&lt;/p&gt;
&lt;p&gt;It also doesn't say that &lt;em&gt;users&lt;/em&gt; should feel bad if their only choice is an old Python 2.7 piece of code. If that software you rely on is written in Python 2.7, and the maintainers long since abandoned it, then yeah that's your only choice and as a person you are perfectly capable of deciding whether that old software is worth the security liability of python 2.7. More often than not, it will be.&lt;/p&gt;
&lt;p&gt;What it &lt;em&gt;does&lt;/em&gt; say is that if you are writing python code today, whether that's new code, or maintaining a project that started over a decade ago, and you intend for others to use that code, and you use Python 2.7, you are a bad programmer and you need to stop what you're doing. Step back, take a deep breath, and uplift your code to a version of Python that is still supported (which realistically means first uplifting to v3, and then going through decade of v3 minor versions to make sure you catch any problems caused by v3 getting better and better), while archiving your 2.7 branch so that folks who absolutely still need it can still get it.&lt;/p&gt;
&lt;h2 id="in-conclusion"&gt;In conclusion&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;If your software still relies on Python 2.7&lt;/strong&gt; , meaning that in 2021, your software that you still work on with the intention of having others make use of it, then&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;your software is bad&lt;/strong&gt; because it forces people into using dead technology that has known security exploits, and&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;you should feel bad&lt;/strong&gt; and you should address that.&lt;/p&gt;
&lt;p&gt;Go archive your 2.7 release as the last 2.7 release you'll ever do, run 2to3 on your code, and start a new release set for 3.x because that's the safe version of Python that people should be using these days.&lt;/p&gt;
&lt;p&gt;Not PHP 4. Or Node 0.10. Or Java 1.4. Or Python 2.7&lt;/p&gt;
</description>
<category>python</category>
<category>programming</category>
<link>http://pomax.github.io/#gh-weblog-1617908788691</link>
<guid>http://pomax.github.io/#gh-weblog-1617908788691</guid>
<pubDate>Thu, 08 Apr 2021 19:06:28 GMT</pubDate>
</item>
<item>
<title> bash_profile for Windows' CMD </title>
<description>&lt;p&gt;Some folks love powershell. I am not one of those people: powershell breaks on standard command chaining using &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;, making it decidedly useless for the work I do on the daily. Instead I use &lt;code&gt;cmd&lt;/code&gt; for everything terminal-related. No "git bash", no "console2", just plain &lt;code&gt;cmd&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;And did you know that &lt;code&gt;cmd&lt;/code&gt; has autorun functionality just like &lt;code&gt;bash&lt;/code&gt; does? It doesn't use a &lt;code&gt;.bash_profile&lt;/code&gt; (obviously) but it does let you specify what should run any time you start &lt;code&gt;cmd&lt;/code&gt; by looking at two special registry keys mentioned in &lt;a href="https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/cmd"&gt;the documentation for cmd&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Cmd.exe looks for the following registry subkeys:

- HKEY_LOCAL_MACHINE\Software\Microsoft\Command Processor\AutoRun (REG_SZ)
- HKEY_CURRENT_USER\Software\Microsoft\Command Processor\AutoRun (REG_EXPAND_SZ)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So, run &lt;code&gt;regedit&lt;/code&gt; and find your way to &lt;code&gt;HKEY_CURRENT_USER\Software\Microsoft&lt;/code&gt;, create the &lt;code&gt;Command Processor&lt;/code&gt; key if it doesn't exist (which it won't if you never used it before), and then create an expandable string value called &lt;code&gt;AutoRun&lt;/code&gt; (paying attention to correct capitalization) and assign it the value &lt;code&gt;%USERPROFILE%\cmd-autorun.bat&lt;/code&gt;, then create a file called &lt;code&gt;cmd-autorun.bat&lt;/code&gt; in your own Windows user directory.&lt;/p&gt;
&lt;p&gt;Done: you now have the equivalent of a &lt;code&gt;.bash_profile&lt;/code&gt; for &lt;code&gt;cmd&lt;/code&gt; that will run only for your user account (as it should be) any time you (or anything else) starts up &lt;code&gt;cmd&lt;/code&gt;.&lt;/p&gt;
</description>
<category>windows</category>
<category>cmd</category>
<category>bash</category>
<category>bash_profile</category>
<category>autorun</category>
<link>http://pomax.github.io/#gh-weblog-1616607431740</link>
<guid>http://pomax.github.io/#gh-weblog-1616607431740</guid>
<pubDate>Wed, 24 Mar 2021 17:37:11 GMT</pubDate>
</item></channel>
</rss>

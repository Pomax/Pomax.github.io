<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<atom:link href="http://pomax.github.io/gh-weblog-2/rss.xml" rel="self" type="application/rss+xml" />
<title>Pomax.github.io</title>
<description>My blog on github</description>
<link>http://pomax.github.io</link>
<lastBuildDate>Tue, 28 May 2024 09:13:46 GMT</lastBuildDate>
<pubDate>Tue, 28 May 2024 09:13:46 GMT</pubDate>
<ttl>1440</ttl>
<item>
<title> Dealing with phantom images in Lightroom</title>
<description>&lt;p&gt;Ever run into a Lightroom showing you this?&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/stuck-image/initial-view.jpg" alt="initial stuck image view"&gt;&lt;/p&gt;
&lt;p&gt;Lightroom shows you an image in your grid and strip views, but it's also super obvious there isn't actually an image file backing it. No filename, no metadata, just nothing. And you can't remove it: LR just ignores your delete button, and your context-menu-initiated "remove photo", and when you tell LR to optimize your catalog in the hopes of clearing this up, it's still there.&lt;/p&gt;
&lt;p&gt;When this happens, the quickest solution is to fix your light room catalog by &lt;em&gt;not using lightroom&lt;/em&gt; and instead using one of the most used tools in the industry: Sqlite3. Sqlite is a file-based database management system, where a single file is a single data, which makes it ideal as a file format for applications, and you'll find it everywhere. Including lightroom. In fact...&lt;/p&gt;
&lt;h2 id="-lrcat-files-are-literally-just-sqlite3-databases"&gt;.lrcat files are literally just Sqlite3 databases&lt;/h2&gt;
&lt;p&gt;You can tell any tool that lets you work with Sqlite databases to load your .lrcat file, and it will just do that for you. And because it's just a database, you can query it: say you wanted the filename list of all your photos that you haven't tagged yet. You can ask Lightroom to do this, but it'll take &lt;em&gt;forever&lt;/em&gt; if you have a large catalog. Or you can query the lrcat database directly and get the answer in a few milliseconds:&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-sqlite"&gt;SELECT
  originalFilename as filename
FROM
  Adobe_images as imageRecord,
  AgLibraryFile as file
WHERE
  imageRecord.rootFile = file.id_local
AND
  imageRecord.id_local NOT IN (
    SELECT DISTINCT(image) FROM AgLibraryKeywordImage
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that speed is not hyperbole: directly using Sqlite means you're bypassing everything except the thing you're interested in, and so it can run &lt;em&gt;really&lt;/em&gt; fast compared to running an operation in Lightroom.&lt;/p&gt;
&lt;h2 id="finding-our-bad-image"&gt;Finding our bad image&lt;/h2&gt;
&lt;p&gt;There's a surprisingly simple way to find our bad image: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;With Lightroom closed, copy our lrcat file to a new file called &lt;code&gt;a.db&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Open Lightroom, and change one thing about the bad image, like flagging it, or adding it to the quick collection.&lt;/li&gt;
&lt;li&gt;Close lightroom, then copy our updated lrcat file to a new file called &lt;code&gt;b.db&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Then, take advantage of &lt;a href="https://www.sqlite.org/sqldiff.html"&gt;sqldiff&lt;/a&gt;, which is a tool that comes with sqlite3 that lets you compare two databases in a normal, human readable way.&lt;/p&gt;
&lt;h2 id="adding-our-image-to-the-quick-collection"&gt;Adding our image to the quick collection&lt;/h2&gt;
&lt;p&gt;Let's look at what happens when we use the quick collection as our method of "finding out what changed":&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-sqlite"&gt;UPDATE Adobe_variablesTable SET value=1696396.0 WHERE id_local=1;
UPDATE Adobe_variablesTable SET value='5EE3773B-1CC4-400B-8886-336773BA06DB' WHERE id_local=7;
UPDATE Adobe_variablesTable SET value='volumeInfo = {'||X'0a09'
||'["D:\\"] = {'||X'0a0909'
||'expanded = true,'||X'0a0909'
||'freeSpace = 12345678,'||X'0a0909'
||'name = "Some Drive (C:)",'||X'0a0909'
||'offline = false,'||X'0a0909'
||'size = 12345678,'||X'0a09'
||'},'||X'0a'
||'}'||X'0a' WHERE id_local=54;
UPDATE Adobe_variablesTable SET value='s = {'||X'0a09'
||'{'||X'0a0909'
||'type = "collection",'||X'0a0909'
||'value = {'||X'0a090909'
||'collectionId = 441740,'||X'0a090909'
||'creationId = "com.adobe.ag.library.smart_collection",'||X'0a090909'
||'tableName = "AgLibraryCollection",'||X'0a0909'
||'},'||X'0a09'
||'},'||X'0a'
||'}'||X'0a' WHERE id_local=55;
UPDATE Adobe_variablesTable SET value='C16EE445-1362-4410-9996-617C7092D74A' WHERE id_local=121;
UPDATE Adobe_variablesTable SET value=738175364.159989 WHERE id_local=131;
UPDATE AgDNGProxyInfo SET statusDateTime='2024-05-23 16:41:17' WHERE id_local=1688612;
UPDATE AgDNGProxyInfo SET statusDateTime='2024-05-23 16:41:17' WHERE id_local=1688616;
[...a whole lot more of these statusDateTime update...]
UPDATE AgDNGProxyInfo SET statusDateTime='2024-05-23 16:41:17' WHERE id_local=1689090;
UPDATE AgDNGProxyInfo SET statusDateTime='2024-05-23 16:41:17' WHERE id_local=1689092;
DELETE FROM AgLibraryCollectionImage WHERE id_local=1681399;
INSERT INTO AgLibraryCollectionImage(id_local,collection,image,pick,positionInCollection) VALUES(1696395,5,1672248,0.0,NULL);
INSERT INTO AgLibraryCollectionImageChangeCounter(rowid,collectionImage,collection,image,changeCounter) VALUES(1,1696395,5,1672248,132891);
DELETE FROM AgLibraryCollectionImageChangeCounter WHERE rowid=2;
DELETE FROM AgSpecialSourceContent WHERE id_local=1665;
INSERT INTO AgSpecialSourceContent(id_local,content,owningModule,source) VALUES(1667,NULL,'com.adobe.ag.library.filter','entire_library');
UPDATE LrMobileSyncChangeCounter SET changeCounter=132891 WHERE rowid=1;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That's a lot of stuff, but it's the &lt;code&gt;AgLibraryCollectionImageChangeCounter&lt;/code&gt; bit we care about, because we only changed a single thing for a single image. If we add some white space to make things a little more obvious, we see:&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-sqlite"&gt;INSERT INTO AgLibraryCollectionImageChangeCounter
  (   rowid  ,  collectionImage  ,  collection  ,   image  ,  changeCounter  )
VALUES
  (     1    ,       1696395     ,       5      ,  1672248  ,    132891      );
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This tells us that there was a change to the image with its own numerical identifier &lt;code&gt;1672248&lt;/code&gt;, stored in the "collection list" with identifier &lt;code&gt;1696395&lt;/code&gt;, in a collection with identifier &lt;code&gt;5&lt;/code&gt;. So let's quickly make sure this is, indeed, the quick collection using (in this case, but you have plenty of options) &lt;a href=""&gt;db browser for sqlite&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src="./image-20240523100618223.png" alt="image-20240523100618223"&gt;&lt;/p&gt;
&lt;p&gt;Collection 5 is indeed the quick collection: perfect, we can now confidently say that our offending image has &lt;code&gt;1672248&lt;/code&gt; as its identifier.&lt;/p&gt;
&lt;h2 id="removing-the-offender-from-the-catalog"&gt;Removing the offender from the catalog&lt;/h2&gt;
&lt;p&gt;So, let's look up our image: the lrcat database stores this information in the &lt;code&gt;Adobe_images&lt;/code&gt; table, so if we look up the record with &lt;code&gt;id_local=1672248&lt;/code&gt; we get:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;id_local: 1672248
id_global: 42A3E56C-D027-4E71-AFF3-6A1907189580
aspectRatioCache: 0.654052734375
bitDepth: 8.0
captureTime: 2023-12-29T09:32:04
colorChannels: 3.0
colorLabels:
colorMode: 2.0
copyCreationTime: -63113817600.0
copyName:
copyReason:
developSettingsIDCache: 1675643.0
fileFormat: JPG
fileHeight: 4096.0
fileWidth: 2679.0
hasMissingSidecars:
masterImage:
orientation: AB
originalCaptureTime:
originalRootEntity:
panningDistanceH:
panningDistanceV:
pick: 0.0
positionInFolder: z
propertiesCache: 1675639.0
pyramidIDCache: none
rating:
rootFile: 1675632
sidecarStatus: 0.0
touchCount: 1.0
touchTime: 731557537.900445
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That's a bunch of stuff! But really what we want to do is delete this image, so most of these values don't matter, and we really only care about these four:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;id_local: 1672248
developSettingsIDCache: 1675643.0
propertiesCache: 1675639.0
rootFile: 1675632
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;The first is the image's identifier in the image table. &lt;/li&gt;
&lt;li&gt;The second is the identifier for the associated record in the &lt;code&gt;Adobe_imageDevelopSettings&lt;/code&gt; table&lt;/li&gt;
&lt;li&gt;The third is the identifier for the associated record in the &lt;code&gt;Adobe_imageProperties&lt;/code&gt; table&lt;/li&gt;
&lt;li&gt;The last is the identifier for the associated record in the &lt;code&gt;AgLibraryFile&lt;/code&gt; table, and &lt;em&gt;that&lt;/em&gt; is where the problem will be: this table houses all the information of which real, on-disk files, map to virtual, in-database image records.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And wouldn't you know it: if we check the &lt;code&gt;AgLibraryFile&lt;/code&gt; table and try to find the record with &lt;code&gt;id_local=1675632&lt;/code&gt;,  there isn't one.&lt;/p&gt;
&lt;h2 id="fixing-this-database"&gt;Fixing this database&lt;/h2&gt;
&lt;details&gt;
&lt;summary&gt;
In order to find out all the places that we'll need to update we can dump our catalog as a SQL file, and then search through it with any decent text editor. When we do, we find that there are 19 places where we may need to intervene.
&lt;/summary&gt;

&lt;code&gt;sql
INSERT INTO "Adobe_variablesTable" ("id_local","id_global","name","type","value") VALUES (58,'221CBFD1-EEB2-43C8-87FC-3F75D3F894D1','Adobe_selectedImages',NULL,'1672248');

INSERT INTO "Adobe_variablesTable" ("id_local","id_global","name","type","value") VALUES (119,'7C2C8795-99C7-40B0-A09D-2741B7C2A41B','Adobe_activeImage',NULL,1672248.0);

INSERT INTO "Adobe_AdditionalMetadata" ("id_local","id_global","additionalInfoSet","embeddedXmp","externalXmpIsDirty","image","incrementalWhiteBalance","internalXmpDigest","isRawFile","lastSynchronizedHash","lastSynchronizedTimestamp","metadataPresetID","metadataVersion","monochrome","xmp") VALUES (1675637,'8AACD130-AD4B-4DCC-8B7D-AA12B813B271',1,1,0,1672248,1,'4fde0a6f3d30508ca3e261e7cdbd6e68',0,'86ca238116b8d1f15db8c9b11d2438ed',725651033.202449,NULL,4.0,0,X'...');

INSERT INTO "AgMetadataSearchIndex" ("id_local","exifSearchIndex","image","iptcSearchIndex","otherSearchIndex","searchIndex") VALUES (1675634,'/t24.7/twindows/tadobe/tphotoshop/t',1672248,'','','/t24.7/twindows/tadobe/tphotoshop/t');

INSERT INTO "Adobe_imageProperties" ("id_local","id_global","image","propertiesString") VALUES (1675639,'C5995A56-D83B-4011-A4D6-3584FEEF15EA',1672248,'...');

INSERT INTO "Adobe_libraryImageDevelopHistoryStep" ("id_local","id_global","dateCreated","digest","hasBigData","hasDevelopAdjustments","image","name","relValueString","text","valueString") VALUES (1675645,'16100BEF-7075-43E8-BAD1-6E25DA321339',726620486.645848,'35e2f635a9912238fcab57e4278ee1b5',0,-1.0,1672248,'Import (1/10/2024 3:01:26 PM)',NULL,X'...',NULL);

INSERT INTO "Adobe_images" ("id_local","id_global","aspectRatioCache","bitDepth","captureTime","colorChannels","colorLabels","colorMode","copyCreationTime","copyName","copyReason","developSettingsIDCache","fileFormat","fileHeight","fileWidth","hasMissingSidecars","masterImage","orientation","originalCaptureTime","originalRootEntity","panningDistanceH","panningDistanceV","pick","positionInFolder","propertiesCache","pyramidIDCache","rating","rootFile","sidecarStatus","touchCount","touchTime") VALUES (1672248,'42A3E56C-D027-4E71-AFF3-6A1907189580',0.654052734375,8.0,'2023-12-29T09:32:04',3.0,'',2.0,-63113817600.0,NULL,NULL,1675643.0,'JPG',4096.0,2679.0,NULL,NULL,'AB',NULL,NULL,NULL,NULL,0.0,'z',1675639.0,'none',NULL,1675632,0.0,1.0,731557537.900445);

INSERT INTO "AgDevelopAdditionalMetadata" ("id_local","hasDepthMap","image") VALUES (1675636,0,1672248);

INSERT INTO "AgLibraryCollectionImage" ("id_local","collection","image","pick","positionInCollection") VALUES (1681399,5,1672248,0.0,NULL);

INSERT INTO "AgLibraryIPTC" ("id_local","caption","copyright","image") VALUES (1675641,NULL,NULL,1672248);

INSERT INTO "AgLibraryImportImage" ("id_local","image","import") VALUES (1677291,1672248,1672136);

INSERT INTO "AgSourceColorProfileConstants" ("id_local","image","profileName") VALUES (1675635,1672248,'Untagged');

INSERT INTO "Adobe_imageDevelopSettings" ("id_local","allowFastRender","beforeSettingsIDCache","croppedHeight","croppedWidth","digest","fileHeight","fileWidth","grayscale","hasBigData","hasDevelopAdjustments","hasDevelopAdjustmentsEx","historySettingsID","image","processVersion","profileCorrections","removeChromaticAberration","settingsID","snapshotID","text","validatedForVersion","whiteBalance") VALUES (1675643,NULL,NULL,NULL,'uncropped','35e2f635a9912238fcab57e4278ee1b5',NULL,NULL,0,0,NULL,-1.0,'16100BEF-7075-43E8-BAD1-6E25DA321339',1672248,'15.4',0.0,0.0,'default',NULL,'...
',3.0,'As Shot');

INSERT INTO "AgHarvestedExifMetadata" ("id_local","image","aperture","cameraModelRef","cameraSNRef","dateDay","dateMonth","dateYear","flashFired","focalLength","gpsLatitude","gpsLongitude","gpsSequence","hasGPS","isoSpeedRating","lensRef","shutterSpeed") VALUES (1675647,1672248,NULL,NULL,NULL,29.0,12.0,2023.0,NULL,NULL,NULL,NULL,0.0,0,NULL,NULL,NULL);

INSERT INTO "AgHarvestedIptcMetadata" ("id_local","image","cityRef","copyrightState","countryRef","creatorRef","isoCountryCodeRef","jobIdentifierRef","locationDataOrigination","locationGPSSequence","locationRef","stateRef") VALUES (1675649,1672248,NULL,NULL,NULL,NULL,NULL,NULL,'unset',-1.0,NULL,NULL);

INSERT INTO "AgHarvestedDNGMetadata" ("id_local","image","hasFastLoadData","hasLossyCompression","isDNG","isHDR","isPano","isReducedResolution") VALUES (1675651,1672248,0,0,0,0,0,0);

INSERT INTO "AgLibraryImageChangeCounter" ("image","changeCounter","changedAtTime","localTimeOffsetSecs") VALUES (1672248,132734,'2024-03-08T02:25:37.902Z',-28800);

INSERT INTO "AgLibraryImageSyncedAssetData" ("image","payloadKey","payloadData") VALUES (1672248,'/changedOnDevice','YvtugebbzQrfxgbc');

INSERT INTO "AgLibraryCollectionImageChangeCounter" ("collectionImage","collection","image","changeCounter") VALUES (1681399,5,1672248,132505);&lt;/code&gt;

&lt;/details&gt;

&lt;p&gt;That's a lot of text! But also: only 19 places where we need to delete a record, and we can do that pretty efficiently with SQL.&lt;/p&gt;
&lt;h3 id="updating-adobe_variablestable-"&gt;Updating &lt;code&gt;Adobe_variablesTable&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;We're going to set both the &lt;code&gt;Adobe_selectedImages&lt;/code&gt; and &lt;code&gt;Adobe_activeImage&lt;/code&gt; fields that currently point to our non-existent image to empty. Depending on the DB manager you're using this could be a simple matter of directly editing the field, but you can also do this using SQL (obviously):&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-javascript"&gt;UPDATE Adobe_variablesTable SET value = '' WHERE name = 'Adobe_selectedImages';
UPDATE Adobe_variablesTable SET value = '' WHERE name = 'Adobe_activeImage';
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="deleting-all-references-to-our-non-existent-image"&gt;Deleting all references to our non-existent image&lt;/h3&gt;
&lt;p&gt;All that's left now is to remove references to our image from the various tables. Again, we can either do this manually, or we can use some SQL:&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-javascript"&gt;DELETE FROM Adobe_AdditionalMetadata WHERE image = 1672248;
DELETE FROM AgMetadataSearchIndex WHERE image = 1672248;
DELETE FROM Adobe_imageProperties WHERE image = 1672248;
DELETE FROM Adobe_libraryImageDevelopHistoryStep WHERE image = 1672248;
DELETE FROM Adobe_images WHERE id_local = 1672248;
DELETE FROM AgDevelopAdditionalMetadata WHERE image = 1672248;
DELETE FROM AgLibraryCollectionImage WHERE image = 1672248;
DELETE FROM AgLibraryIPTC WHERE image = 1672248;
DELETE FROM AgLibraryImportImage WHERE image = 1672248;
DELETE FROM AgSourceColorProfileConstants WHERE image = 1672248;
DELETE FROM Adobe_imageDevelopSettings WHERE image = 1672248;
DELETE FROM AgHarvestedExifMetadata WHERE image = 1672248;
DELETE FROM AgHarvestedIptcMetadata WHERE image = 1672248;
DELETE FROM AgHarvestedDNGMetadata WHERE image = 1672248;
DELETE FROM AgLibraryImageChangeCounter WHERE image = 1672248;
DELETE FROM AgLibraryImageSyncedAssetData WHERE image = 1672248;
DELETE FROM AgLibraryCollectionImageChangeCounter WHERE image = 1672248;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we're dealing with the identifier from the &lt;code&gt;Adobe_images&lt;/code&gt; so we're deleting from that table using &lt;code&gt;id_local&lt;/code&gt; whereas we're deleting from every other table using &lt;code&gt;image&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="how-did-we-do-"&gt;How did we do?&lt;/h2&gt;
&lt;p&gt;If we now open Lightroom on our updated catalog, what do we see?&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/image-20240523111441729.png" alt="image-20240523111441729"&gt;&lt;/p&gt;
&lt;p&gt;And that's our problem solved. No more phantom image. It's a good idea to run a (hopefully) quick catalog optimization, but other than that, it's back to not having to deal with this problem hopefully forever!&lt;/p&gt;
</description>

<link>http://pomax.github.io/#gh-weblog-1716887502084</link>
<guid>http://pomax.github.io/#gh-weblog-1716887502084</guid>
<pubDate>Tue, 28 May 2024 09:11:42 GMT</pubDate>
</item>
<item>
<title> Socketless, a websocket-based RPC library... without websockets or RPC</title>
<description>&lt;p&gt;I released &lt;a href="https://github.com/pomax/socketless"&gt;socketless&lt;/a&gt; v1.0.0 today, which is a websockets-based RPC library for Node-based client/server implementations, that removes all the websocket and RPC nonsense: you write normal JS code, your client and server see a &lt;code&gt;this.server&lt;/code&gt; and &lt;code&gt;this.clients[...]&lt;/code&gt; respectively, and if they need to call server and client functions respectively, they just... do that. Without ever knowing that the client or server is running on a completely different machine half the world away.&lt;/p&gt;
&lt;p&gt;Obviously, this solves a problem for me: I hate writing websocket code, I just want to call functions and get return values, so maybe this is useful for you, too. &lt;/p&gt;
&lt;p&gt;I still need to set up a website for it (for now, the github repo will do), and I want to swap over my &lt;a href="https://pomax.github.io/are-we-flying/"&gt;"Are we flying?"&lt;/a&gt; article and codebase to make use of this (as well as an unreleased multiplayer Mahjong implementation, more on that in the future, hopefully), which I'm sure will reveal things I still need to add or change, but for now, this is incredibly useful as is, and if you've ever wanted to write a client/server "anything", be it a game, chat server, BBS, whathaveyou, this should make that jobs a ridiculous amount easier.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/pomax/pomax.github.io/issues"&gt;Let me know what you think!&lt;/a&gt;&lt;/p&gt;
</description>
<category>Nodejs</category>
<category>websocket</category>
<category>websockets</category>
<category>RPC</category>
<category>games</category>
<link>http://pomax.github.io/#gh-weblog-1697948473746</link>
<guid>http://pomax.github.io/#gh-weblog-1697948473746</guid>
<pubDate>Sun, 22 Oct 2023 04:21:13 GMT</pubDate>
</item>
<item>
<title> A sweet, mild hot sauce</title>
<description>&lt;p&gt;We're running out of a mild hot sauce that we quite like, so I figured I might as well try to replicate the recipe. The following makes about 60oz/1.75L&lt;/p&gt;
&lt;p&gt;Ingredients:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jalapeno: x15~x20&lt;/li&gt;
&lt;li&gt;Habanero x6&lt;/li&gt;
&lt;li&gt;Tomatillo: x5 (small)&lt;/li&gt;
&lt;li&gt;Cilantro: 1 bunch (stems and all)&lt;/li&gt;
&lt;li&gt;Cumin: 3 tbsp&lt;/li&gt;
&lt;li&gt;Onion powder: 4 tbsp&lt;/li&gt;
&lt;li&gt;Black pepper: 1 tbsp&lt;/li&gt;
&lt;li&gt;Garlic paste: 5 tbsp&lt;/li&gt;
&lt;li&gt;Rock Salt: 35gr (1.5 tbsp)&lt;/li&gt;
&lt;li&gt;Thick apricot jam: 2.5 cups&lt;/li&gt;
&lt;li&gt;Apple cider vinegar: 1.5 cups&lt;/li&gt;
&lt;li&gt;Apple Juice: 0.5 cup&lt;/li&gt;
&lt;li&gt;Lemon juice:  4 tbsp&lt;/li&gt;
&lt;li&gt;Lime juice: 2 tbsp&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;blend&lt;/li&gt;
&lt;li&gt;keep blending.&lt;/li&gt;
&lt;li&gt;keep it up!&lt;/li&gt;
&lt;li&gt;yeah you're probably done.&lt;/li&gt;
&lt;/ol&gt;
</description>
<category>hot sauce</category>
<link>http://pomax.github.io/#gh-weblog-1697686323351</link>
<guid>http://pomax.github.io/#gh-weblog-1697686323351</guid>
<pubDate>Thu, 19 Oct 2023 03:32:03 GMT</pubDate>
</item>
<item>
<title> Writing a Node package using Rust... on Windows</title>
<description>&lt;p&gt;Let me preface this by saying that every single person who claims that &lt;code&gt;mingw&lt;/code&gt;, or &lt;code&gt;msys&lt;/code&gt;, or "you have &lt;code&gt;WSL2&lt;/code&gt;, just use that" are valid excuses to not target actual Windows is actively making life worse for large swathes of developers, and if that's you, please be better. Applications and libraries should work on any OS, including Windows: just cross-platform compile your software instead of making it someone else's problem =)&lt;/p&gt;
&lt;p&gt;With that out of the way: let's write some code in Rust that we can call from Node.js so that we get the best of both worlds: the ease of development of Node.js, with the "I need this to be fast" parts handled by natively compiled code.&lt;/p&gt;
&lt;p&gt;First up, let's get Rust configured:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/llvm/llvm-project/releases/ because you'll need LLD (click &amp;quot;show all ... assets&amp;quot; and download the windows version"&gt;install LLVM&lt;/a&gt;, because we'll need the LLD tool that comes with it,&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.rust-lang.org/tools/install"&gt;install Rust&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;check to see if you have a &lt;code&gt;C:\Users\yournamehere\.cargo\config&lt;/code&gt; file. If you don't, create one, and&lt;/li&gt;
&lt;li&gt;run &lt;code&gt;rustup target add x86_64-pc-windows-msvc&lt;/code&gt; to download the bits Rust needs to build native Windows binaries.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then open the cargo config file, and add the following to it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[target.x86_64-pc-windows-msvc]
linker = "lld-link.exe"
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Rust now knows that it's building for the Windows platform. Beauty.&lt;/p&gt;
&lt;p&gt;Next up, we'll need Node.js&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;install &lt;a href="https://github.com/coreybutler/nvm-windows"&gt;nvm-windows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;run &lt;code&gt;nvm install lts&lt;/code&gt; to install the current &lt;a href="https://en.wikipedia.org/wiki/Long-term_support"&gt;LTS&lt;/a&gt; version of Node&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And we're good to go. Let's start by creating a new project by running &lt;code&gt;cargo new testlib&lt;/code&gt; and then changing a few things because we want Rust to build us a library, not an executable:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;rename &lt;code&gt;src/main.rs&lt;/code&gt; to &lt;code&gt;src/lib.rs&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;add a section called &lt;code&gt;[lib]&lt;/code&gt; to the &lt;code&gt;Cargo.toml&lt;/code&gt; file, and&lt;/li&gt;
&lt;li&gt;add &lt;code&gt;crate-type = ["cdylib"]&lt;/code&gt; in that new section.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This tells Rust that it will be compiling a shared library appropriate to the OS we build it on. Since we're on Windows, it'll be generating &lt;code&gt;.dll&lt;/code&gt; files.&lt;/p&gt;
&lt;p&gt;And with that, let's put some Rust code in our &lt;code&gt;lib.rs&lt;/code&gt;!&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-rust"&gt;// Tell Rust that we want our ABI to be C flavoured:

#[repr(C)]

// Create the equivalent of a Vec3:

pub struct Orientation {
  pitch: f64,
  roll: f64,
  yaw: f64,
}

// Give that struct an .add() function:

impl Orientation {
  fn add(&amp;amp;mut self, pitch: f64, roll: f64, yaw:f64) -&amp;gt; &amp;amp;mut Orientation {
    self.pitch += pitch;
    self.roll += roll;
    self.yaw += yaw;
    return self;
  }
}

// And then let's write a function that takes an Orientation as input,
// does "something", and then returns that Orietation as output:

#[no_mangle]
pub extern fn orientation_test(s: &amp;amp;mut Orientation) -&amp;gt; &amp;amp;mut Orientation {
  return s.add(1.0, 2.0, 3.0);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you're familiar with Rust none of this should be too surprising, but you might notice the &lt;code&gt;#[repr(C)]&lt;/code&gt;, which tells Rust that we want the library's &lt;a href="https://en.wikipedia.org/wiki/Application_binary_interface"&gt;application binary interface&lt;/a&gt; (ABI) to conform to the C version, because Node only knows how to work with C flavoured ABIs. You might also notice the &lt;code&gt;#[no_mangle]&lt;/code&gt; which is &lt;em&gt;super&lt;/em&gt; important: by default Rust will optimize function names, which is convenient for generating smaller executables but is &lt;em&gt;disastrous&lt;/em&gt; for libraries, where the point is that we want to call functions that we export &lt;em&gt;using the name we gave them&lt;/em&gt;. So we tell Rust not to mangle the function name. And of course, everything we want to make use of on the Node side gets a &lt;code&gt;pub&lt;/code&gt; so that it's visible to the outside world.&lt;/p&gt;
&lt;p&gt;And that's it, we can now run &lt;code&gt;cargo build&lt;/code&gt; and it'll generate us a &lt;code&gt;target/debug/testlib.dll&lt;/code&gt; file to use in "whatever knows how to import DLL files"!&lt;/p&gt;
&lt;p&gt;So let's move on to Node. We're first going to initialize the Rust project as a Node project, too, using &lt;code&gt;npm init&lt;/code&gt;, after which we need to install something that'll let us work with DLL files, i.e. we want an &lt;a href="https://en.wikipedia.org/wiki/Foreign_function_interface"&gt;foreign function interface&lt;/a&gt; (FFI) solution, and the one we'll be using is &lt;a href="https://koffi.dev/"&gt;koffi&lt;/a&gt;: &lt;code&gt;npm install koffi&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;(There are other options, but after trying pretty much every FFI solution that exists for Node, &lt;code&gt;koffi&lt;/code&gt; was by far the most pleasant to work with. Which is pretty important!)&lt;/p&gt;
&lt;p&gt;We then edit our &lt;code&gt;package.json&lt;/code&gt; to include a &lt;code&gt;"type": "module"&lt;/code&gt; because it's 2023 and we'll be writing modern JS with modern ES modules instead of using the legacy Node-only CommonJS module system, and we're good to go, let's create a &lt;code&gt;test.js&lt;/code&gt; and make it use our DLL file!&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-js"&gt;// First we import koffi and load our library, using the extension appropriate to our OS.
// Remember, just because we're on Windows doesn't mean we should be LOCKED into Windows!

import koffi from "koffi";
const libraryPath = `./target/debug/testlib.${process.platform === `win32` ? `dll` : `so`}`;
const lib = koffi.load(libraryPath);

// Then we'll need a JS-equivalent of the struct our library uses:

const Orientation = koffi.struct(`Orientation`, {
  pitch: `double`,
  roll: `double`,
  yaw: `double`,
});

// And of course, we need a function handle, which requires specifying the function name we
// want from the library, as well as what output it generates, given which inputs:

const orientationTest = lib.func(`orientation_test`, Orientation, [Orientation]);

// And with that we're ready to run some native code!

const data = {
  pitch: 0,
  roll: 0,
  yaw: 0,
};

let result = data;

const start = performance.now();
for(let i=0; i&amp;lt;10000; i++) {
  result = orientationTest(result);
}
const timeTaken = (performance.now() - start)|0;

console.log(`test result:`, result, `- 10,000 iterations took ${timeTaken}ms`);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we now run this using &lt;code&gt;node test.js&lt;/code&gt; we see:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;test result: { pitch: 10000, roll: 20000, yaw: 30000 } - 10,000 iterations took 13ms
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;How cool is that? We're no longer stuck with running code at the speed of JS, we can run code at &lt;em&gt;native&lt;/em&gt; speed by handing the number-crunchy, resource-intensive parts over to Rust, while keeping the convenience of JS for all the other parts of our code. It's the best of both worlds!&lt;/p&gt;
</description>
<category>Node.js</category>
<category>Rust</category>
<category>Koffi</category>
<category>FFI</category>
<link>http://pomax.github.io/#gh-weblog-1691255244859</link>
<guid>http://pomax.github.io/#gh-weblog-1691255244859</guid>
<pubDate>Sat, 05 Aug 2023 17:07:24 GMT</pubDate>
</item>
<item>
<title> Generating a 3D LUT with Photoshop for OBS/Atomos/etc.</title>
<description>&lt;p&gt;Have you ever needed a 3D cube LUT? Turns out, all you need is Photoshop! Whip out Photoshop and create a bunch of "adjustment layers" for your colour correction...&lt;/p&gt;
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/177243/235992202-f9203283-9437-4c28-95f8-70555804c527.png" alt="image"&gt;&lt;/p&gt;
&lt;p&gt;And then export that to a LUT using "export" -&amp;gt; "Color Lookup Tables..." with only "CUBE" as format and 32 points. Brilliant: instant 33 point 3d LUT for use in OBS, your video monitor,  in-camera, through a LUT box, etc. etc.!&lt;/p&gt;
&lt;p&gt;But then you load it into OBS, or your LUT box, and oh no your video feed suddenly looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/177243/234699746-5c492161-e373-4e57-b4fb-a43c7a7c4d42.png" alt="{C9DE6C3A-EC6B-492A-A830-9B29F1A70590}"&gt;&lt;/p&gt;
&lt;p&gt;The problem you're seeing is almost certainly caused by having multiple image layers under your adjustment layer(s):&lt;/p&gt;
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/177243/234700423-866d74a7-a68a-4c0a-a81d-feea987a42f3.png" alt="image"&gt;&lt;/p&gt;
&lt;p&gt;And the solution is to just flatten all of those, &lt;em&gt;then&lt;/em&gt; export your color adjustments as a cube LUT:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/177243/234700619-56851d7d-04f1-4cf4-96a1-6f84dafaac39.png" alt="image"&gt;&lt;/p&gt;
&lt;p&gt;And presto, suddenly your LUT works just fine in OBS, or your LUT box, or any other context that needs a cube LUT:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/177243/234700798-76327d7a-fa6c-4388-bacc-b4e837789a34.png" alt="image"&gt;&lt;/p&gt;
</description>
<category>3D</category>
<category>cube</category>
<category>lut</category>
<category>photoshop</category>
<category>obs</category>
<link>http://pomax.github.io/#gh-weblog-1682542272279</link>
<guid>http://pomax.github.io/#gh-weblog-1682542272279</guid>
<pubDate>Wed, 26 Apr 2023 20:51:12 GMT</pubDate>
</item>
<item>
<title>Leaving twitter</title>
<description>&lt;p&gt;In October of 2022, Elon Musk, a man who failed up harder than anyone else in history, decided to buy Twitter with the express intent to turn it into a completely different product. He laid off thousands of people, devalued the company by 50%, and started pushing through changes that not only changed the experience of the platform, but also made sure that you had no way of actually seeing the content you wanted, while at the same time pushing ads into every single stream presented to you.&lt;/p&gt;
&lt;p&gt;I signed up for Twitter back in 2009, and it's been a (mostly) fun ride, but even when it wasn't, there were always two things preventing folks from leaving the platform: (1) it was rarely &lt;em&gt;that&lt;/em&gt; bad, and (2) there was no genuine alternative. &lt;/p&gt;
&lt;p&gt;Both those things changed in recent years. For several years now, Mastodon has been an alternative to Twitter, and with Elon's destruction of Twitter the number of both Mastodon users and Mastodon servers has exploded. It's now a perfectly fine alternative with plenty of folks to follow. No, they're not all on the same server, but it's not like you had problems sending emails to people who didn't use your email server before, and this is the same. Just follow them, irrespective of which server they happen to use. Done, you just need to know their "homepage", hardly a chore.&lt;/p&gt;
&lt;p&gt;So as Musk lands more and more garbage features in a desperate attempt to short-term claw back money, I'm calling it quits. To prevent people from namesquatting, I've deleted my account, waiting the prerequisite 30 day period for it to become available again, and reregistered my name but won't be posting using it. Instead, I'll be using mastodon exclusively from now on. &lt;/p&gt;
&lt;p&gt;You can find me over on &lt;a href="https://mastodon.social/@TheRealPomax"&gt;https://mastodon.social/@TheRealPomax&lt;/a&gt;&lt;/p&gt;
</description>
<category>Mastodon</category>
<category>Twitter</category>
<link>http://pomax.github.io/#gh-weblog-1681585670331</link>
<guid>http://pomax.github.io/#gh-weblog-1681585670331</guid>
<pubDate>Sat, 15 Apr 2023 19:07:50 GMT</pubDate>
</item>
<item>
<title> Getting elevation data out of DEM/DSM GeoTIFF files</title>
<description>&lt;p&gt;I'm working on a fun little side project implementing an autopilot in JavaScript to "drive" planes in Microsoft Flight Simulator 2020, and one of the things it needs is an altitude computer/terrain follow system. And in order to make that reasonably accurate, I figured I'd download the entire planet's elevation data in the form of the &lt;a href="https://www.eorc.jaxa.jp/ALOS/en/dataset/aw3d30/aw3d30_e.htm"&gt;ALOS Wolrd 3D (30m)&lt;/a&gt; dataset. This is around 450GB of DSM data, and takes the form of &lt;a href="http://geotiff.maptools.org/spec/geotiff2.html"&gt;GeoTiff&lt;/a&gt; files.&lt;/p&gt;
&lt;p&gt;Conventional GIS wisdom says that in order to work with that, you need to use &lt;a href="https://gdal.org/"&gt;GDAL&lt;/a&gt;, which has no Node bindings, but it has a Python API. And Python's not hard to use, but having to use two different programming languages is inconvenient. So after writing working python GDAL code, which takes 23 seconds to get the full file list of available tiles on my NAS, I figured I'd see if there was a Node library that worked with GDAL anyway.&lt;/p&gt;
&lt;p&gt;Turns out there is, or rather, there are. I ended up using &lt;a href="https://github.com/mmomtchev/node-gdal-async"&gt;gdal-async&lt;/a&gt;, which is a fork of &lt;a href="https://github.com/contra/node-gdal-next"&gt;https://github.com/contra/node-gdal-next&lt;/a&gt;, which is a fork of &lt;a href="https://github.com/naturalatlas/node-gdal"&gt;https://github.com/naturalatlas/node-gdal&lt;/a&gt;,  and reimplementing the logic on the Python side in Node yields a codebase that can index the same files, on the same NAS, in 7 seconds instead of 23. So that's weird, but better than before.&lt;/p&gt;
&lt;p&gt;I ended up writing out the file index to a 24000 line JSON file as a cache, hoping that'd be faster, and where it takes Python a bit to run through that, Node.js loads that instantly. &lt;em&gt;And&lt;/em&gt; parses it to a JS datastructure. The server's just up the moment I run &lt;code&gt;node server.js&lt;/code&gt; instead of spending a second or two starting up. &lt;/p&gt;
&lt;p&gt;But it gets better: why am I using GDAL at all if all I want is the elevations for GPS coordinates? Surely, GeoTIFF is not so complex that only giant GIS projects can make sense of them? And it turns out that, no, it's not. It's in fact near-trivial to write your own code for this provided you know a little bit of programming: GeoTIFF put all the information you need in the "fields" section of an IFD block (the kind of blocks a TIFF file is built up from), so we can just use &lt;a href="https://www.npmjs.com/package/tiff"&gt;a tiff parser&lt;/a&gt; to get those fields, and then look up what values we need in order to map GPS coordinates to TIFF pixel indices (See &lt;a href="https://stackoverflow.com/a/75647596/740553"&gt;https://stackoverflow.com/a/75647596/740553&lt;/a&gt; for an overly detailed explanation on the how!)&lt;/p&gt;
&lt;p&gt;So, how much code is it when we implement the entire thing, bar the TIFF parser, ourselves? This much code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-javascript"&gt;import { existsSync, copyFileSync, readFileSync, writeFileSync } from "fs";
import { basename, join } from "path";
import tiff from "tiff";
const { floor, ceil } = Math;

const __dirname = url.fileURLToPath(new URL(".", import.meta.url));
const INDEX_FILE = join(__dirname, `alos-index.json`);
const CACHE_DIR = join(__dirname, `cache`);
const ALOS_VOID_VALUE = -9999;

class ALOSTile {
  constructor(tilePath) {
    this.tilePath = tilePath;
    // copy to cache dir for faster loading
    const filename = join(`.`, CACHE_DIR, basename(tilePath));
    if (!existsSync(filename)) copyFileSync(tilePath, filename);
    this.init(filename);
  }

  init(filename) {
    const file = readFileSync(filename);
    const image = tiff.decode(file.buffer);
    const block = (this.block = image[0]);
    const fields = block.fields;
    let [sx, sy, sz] = fields.get(33550);
    let [px, py, k, gx, gy, gz] = fields.get(33922);
    sy = -sy;
    this.reverse = [-gx / sx, 1 / sx, 0, -gy / sy, 0, 1 / sy];
    this.pixels = block.data;
  }

  lookup(lat, long) {
    const { reverse: T, block } = this;
    const x = T[0] + T[1] * long + T[2] * lat;
    const y = T[3] + T[4] * long + T[5] * lat;
    const pos = (x | 0) + (y | 0) * block.width;
    const value = this.pixels[pos];
    return value ?? ALOS_VOID_VALUE;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There, that's the entire code &lt;em&gt;plus convenience wrapper&lt;/em&gt; to do an elevation lookup in a GeoTIFF tile. No GDAL, no Python, heck we don't even need to care about which programming language we're using as long as it has a TIFF parser it can use. The rest is just absolutely basic programming.&lt;/p&gt;
</description>
<category>Node</category>
<category>GIS</category>
<category>GDAL</category>
<category>MSFS</category>
<category>MSFS 2020</category>
<category>Elevation</category>
<category>DEM</category>
<category>DSM</category>
<link>http://pomax.github.io/#gh-weblog-1678206967957</link>
<guid>http://pomax.github.io/#gh-weblog-1678206967957</guid>
<pubDate>Tue, 07 Mar 2023 16:36:07 GMT</pubDate>
</item>
<item>
<title>MacOS and external SSDs</title>
<description>&lt;p&gt;Ever had your external SSD refuse to remount when you plug it into MacOS because it's an idiotic OS and remembers you didn't properly ejected it?&lt;/p&gt;
&lt;p&gt;First, kill &lt;code&gt;fsck&lt;/code&gt; (the "file system consistency check" with the dumbest command name) because it's ruining the party right now:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ps aux | grep fsck
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Find the process id and &lt;code&gt;sudo kill -9 thatid&lt;/code&gt; because goddamnit, fsck, stop ruining the party. It's even going to do a fake out, because there's probably two pids, and only one of them is real. The other's a zombie process.&lt;/p&gt;
&lt;p&gt;With the main one killed, we can remount the drive:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ diskutils mount /Volumes/disk3s2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or whatever your disk volume is according to Disk Utility.&lt;/p&gt;
</description>
<category>MacOS</category>
<category>SSD</category>
<category>fsck</category>
<link>http://pomax.github.io/#gh-weblog-1676434414432</link>
<guid>http://pomax.github.io/#gh-weblog-1676434414432</guid>
<pubDate>Wed, 15 Feb 2023 04:13:34 GMT</pubDate>
</item>
<item>
<title> Adding a physical drive to a VMware Workstation VM</title>
<description>&lt;p&gt;If VMWare complains that it has insufficient rights to use a physical drive with adding a hard disk in the VM settings: open computer management with admin rights, then look for that drive in the list. If it has a drive letter: remove the drive letter. &lt;/p&gt;
&lt;p&gt;Remember: adding a physical drive means literally giving it to the guest OS, not "sharing it between the host and the guest", so remove its drive letter in computer management to &lt;em&gt;guarantee&lt;/em&gt; that your host's Windows can't use it. Once done, you can add it to your VM without any problems.&lt;/p&gt;
&lt;p&gt;And if you need to &lt;em&gt;share&lt;/em&gt; drives, just use network sharing. That's what it's for.&lt;/p&gt;
</description>
<category>VMware</category>
<category>Workstation</category>
<category>drive</category>
<category>errors</category>
<link>http://pomax.github.io/#gh-weblog-1672175588471</link>
<guid>http://pomax.github.io/#gh-weblog-1672175588471</guid>
<pubDate>Tue, 27 Dec 2022 21:13:08 GMT</pubDate>
</item>
<item>
<title> Structs in Python</title>
<description>&lt;p&gt;Python does not have syntax for writing C structs, or things that act like them, but thankfully you can write a class decorator that adds something that feels like it should have been in the language from day one.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import copy


def struct(struct_class):
    # extract the struct members
    member_names = []
    member_values = []
    for attr_name in dir(struct_class):
        if not attr_name.startswith('_'):
            value = getattr(struct_class, attr_name)
            if not callable(value):
                member_names.append(attr_name)
                member_values.append(value)

    # create a new init
    def struct_init(self, *args, **kwargs):
        i = 0  # we really don't need enumerate() here...
        for value in args:
            name = member_names[i]
            default_value = member_values[i]
            setattr(self, name, value if value is not None else default_value)
            i += 1  # ...we just need to inc an int
        for key, value in kwargs.items():
            if key in member_names:
                i = member_names.index(key)
                default_value = member_values[i]
                setattr(self, key, value if value is not None else default_value)
        # fall through  to the struct constructor.
        if hasattr(self.__class__, 'constructor'):
            self.constructor(**kwargs)

    # A struct can be iterated over, yielding and ordered list
    # based on member names defined in the struct class.
    def member_iter(self):
        return [copy.deepcopy(getattr(self, name)) for name in member_names].__iter__()

    # Structs do not allow shallow copying. All copies are a deep copies.
    def deep_copy(self):
        return copy.deepcopy(self)

    # rebind and return
    struct_class.__init__ = struct_init
    struct_class.__iter__ = member_iter
    struct_class.__copy__ = deep_copy
    return struct_class
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this, we can write code with nice Struct-likes:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from as_struct import struct

@struct
class Orientation():
    pitch = 0
    roll = 0
    yaw = 0

@struct
class Trim():
    elevator = 0
    aileron = 0
    rudder = 0

class Brrrrrr():
    def __init__(self):
        self.description = "I'm a plane!"
        self.orientation = Orientation()
        self.trim = Trim()

    def trim(self, e=0, a=0, r=0):
        self.trim.elevator += e
        self.trim.aileron += a
        self.trim.rudder += r
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Done.&lt;/p&gt;
</description>
<category>Python</category>
<category>struct</category>
<category>decorator</category>
<link>http://pomax.github.io/#gh-weblog-1671995243640</link>
<guid>http://pomax.github.io/#gh-weblog-1671995243640</guid>
<pubDate>Sun, 25 Dec 2022 19:07:23 GMT</pubDate>
</item></channel>
</rss>

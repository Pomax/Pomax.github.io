<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<atom:link href="http://pomax.github.io/gh-weblog-2/rss.xml" rel="self" type="application/rss+xml" />
<title>Pomax.github.io</title>
<description>My blog on github</description>
<link>http://pomax.github.io</link>
<lastBuildDate>Fri, 01 Jan 2021 18:38:15 GMT</lastBuildDate>
<pubDate>Fri, 01 Jan 2021 18:38:15 GMT</pubDate>
<ttl>1440</ttl>
<item>
<title>Dragging .mid files into FL Studio</title>
<description>&lt;p&gt;There are a few ways to drag midi files into &lt;a href="https://www.image-line.com/"&gt;FL Studio&lt;/a&gt;, but the best way is also not documented:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Drag your .mid onto the program &lt;em&gt;background&lt;/em&gt;, so &lt;strong&gt;not&lt;/strong&gt; onto the channel rack, and &lt;strong&gt;not&lt;/strong&gt; into a pattern, then&lt;/li&gt;
&lt;li&gt;say "no" when asked to save the current project,&lt;/li&gt;
&lt;li&gt;make sure "start new project" is unchecked in the MIDI import dialog, and then&lt;/li&gt;
&lt;li&gt;hit accept: congrats, you're done.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Unlike the &lt;a href="https://www.image-line.com/fl-studio-learning/fl-studio-online-manual/html/automation_midiimport.htm"&gt;officially documented way&lt;/a&gt;, which splits up MIDI events into separate channels for no reason whatsoever, this method preserves the data and will import everything to the same channel if the .mid file had everything in the same channel. No need for the incredibly tedious "importing CC automation one CC at a time" workflow, just drag, drop, click, click, click, done: you now have a new channel rack entry that can play the midi data, and an associated pattern that you can place wherever you want in the arrangement window with all your midi data.&lt;/p&gt;
</description>
<category>MIDI</category>
<category>FL Studio</category>
<link>http://pomax.github.io/#gh-weblog-1609525953375</link>
<guid>http://pomax.github.io/#gh-weblog-1609525953375</guid>
<pubDate>Fri, 01 Jan 2021 18:32:33 GMT</pubDate>
</item>
<item>
<title>Installing Windows 7 in late 2020</title>
<description>&lt;p&gt;I needed to install Windows 7 on an old Shuttle computer, for which win10 would be too much of a constant load on the system (it's a completely passive system, and a constant 30% load on the cpu is very much not appreciated), and ran into an interesting problem. For the most part, installation is fine: get the official ISO from Microsoft on their &lt;a href="https://www.microsoft.com/en-ca/software-download/windows7"&gt;dedicated software download page&lt;/a&gt;, which requires supplying your windows 7 key (conveniently a sticker on the inside of the Shuttle case. Inconveniently, a sticker you can't remove and put in an organizer that has all your software keys).&lt;/p&gt;
&lt;p&gt;Burn the ISO to a USB stick, which can thankfully be any old 4GB stick because windows 7, unlike 10, never grew past 3.5GB as base install (I use &lt;a href="https://sourceforge.net/projects/win32diskimager/"&gt;Win32 Disk Imager&lt;/a&gt;, which can "burn" &lt;code&gt;.iso&lt;/code&gt; files just fine, but you do need to file type filter for all file types, because it'll filter just for &lt;code&gt;.img&lt;/code&gt; files), then boot off of said USB stick.&lt;/p&gt;
&lt;p&gt;Once up and running, you start Windows Update (start → "all programs" → windows update) and then you go through the "install updates, reboot, install more updates, reboot, etc. etc." motions. Until you hit update &lt;code&gt;kb4516065&lt;/code&gt;, which will fail with an error code 80092004 that has no article to explain what it means, and seemingly has no way to get past.&lt;/p&gt;
&lt;p&gt;Thankfully, the advice in &lt;a href="https://answers.microsoft.com/en-us/windows/forum/windows_7-update/kb4516065-installation-fails-with-error-80092004/ef9994ee-7820-436e-b18f-001ae53edf28"&gt;this post&lt;/a&gt; works: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;download and manually install &lt;a href="https://www.catalog.update.microsoft.com/search.aspx?q=kb4490628"&gt;kb4490628&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;then download and manually install &lt;a href="https://www.catalog.update.microsoft.com/Search.aspx?q=kb4516065"&gt;kb4516065&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once done, windows update can get back to the "install updates, reboot, install more updates, reboot, etc" dance and all is well.&lt;/p&gt;
&lt;p&gt;I mean, except for the part where you'll never receive security etc updates ever again, so once you're done installing everything, you &lt;em&gt;prooobably&lt;/em&gt; want to either air gap or network-restrict the machine so it can't reach, or be reached from, the internet. Which is exactly what I need (it just needs to accept audio feeds from a set of microphones that it can then forward on over LAN, no internet required) so happens to be fine for my use-case.&lt;/p&gt;
</description>

<link>http://pomax.github.io/#gh-weblog-1603899270641</link>
<guid>http://pomax.github.io/#gh-weblog-1603899270641</guid>
<pubDate>Wed, 28 Oct 2020 15:34:30 GMT</pubDate>
</item>
<item>
<title>Automating the build process of the Primer on Bezier Curves</title>
<description>&lt;p&gt;If you're reading this, you probably know my &lt;a href="https://pomax.github.io/bezierinfo/"&gt;Primer on Bézier Curves&lt;/a&gt;, but what you probably don't know is that until today this build process for this was entirely manual. A code change would require landing the code, then checking out &lt;code&gt;master&lt;/code&gt;, running &lt;code&gt;npm run build&lt;/code&gt;, then pushing the rebuilt files back up to &lt;code&gt;master&lt;/code&gt;, and then doing the same for the &lt;code&gt;bezierinfo&lt;/code&gt; repo, which exists in parallel.&lt;/p&gt;
&lt;p&gt;Most of that work has now been automated with &lt;a href="https://github.com/features/actions"&gt;Github actions&lt;/a&gt;. Whenever content or build related files get updated on the master branch, Github will now cause &lt;a href="https://github.com/Pomax/BezierInfo-2/blob/master/.github/workflows/ci.yml"&gt;ci.yml&lt;/a&gt; to kick in, which runs through the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;check out &lt;code&gt;master&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Install &lt;a href="https://www.tug.org/texlive"&gt;TeX Live&lt;/a&gt;, which installs all the TeX features that the primer relies on&lt;/li&gt;
&lt;li&gt;Pulls the &lt;code&gt;pdf2svg&lt;/code&gt; source code from the web and builds it&lt;/li&gt;
&lt;li&gt;Grabs &lt;a href="https://github.com/nvm-sh/nvm"&gt;nvm&lt;/a&gt; and uses it to install the latest version of Node and runs &lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Runs &lt;code&gt;npm run build&lt;/code&gt;, which runs &lt;a href="https://github.com/Pomax/BezierInfo-2/blob/master/webpack.config.js"&gt;webpack several times&lt;/a&gt;, once for each locale, which:&lt;ul&gt;
&lt;li&gt;preprocesses the souce code to &lt;a href="https://github.com/Pomax/BezierInfo-2/blob/master/lib/latex-loader.js"&gt;replace LaTeX code with &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; tags&lt;/a&gt; by literally wrapping it in a LaTeX document and then calling &lt;a href="https://en.wikipedia.org/wiki/XeTeX"&gt;xelatex&lt;/a&gt; on that source,&lt;/li&gt;
&lt;li&gt;crops the resulting PDF, then&lt;/li&gt;
&lt;li&gt;converts that crop to an SVG image on disk, then&lt;/li&gt;
&lt;li&gt;reads in the SVG image's dimensions so the original source can be replaced with &lt;code&gt;&amp;lt;img src="..." width="..." height="..."&amp;gt;&lt;/code&gt;, ensuring the document doesn't constantly reflow as images load in, then&lt;/li&gt;
&lt;li&gt;wraps all example code such that references to the graphics API, which cannot possibly work in isolation, actually point to the right thing, and then finally,&lt;/li&gt;
&lt;li&gt;runs the result through babel and bundles it up as &lt;code&gt;article.js&lt;/code&gt; with its own &lt;code&gt;index.html&lt;/code&gt; (because each locale needs an appropriate&lt;code&gt;lang=...&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Commits and pushes the result back up to &lt;code&gt;master&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So the only thing I still need to do manually now is sync from the &lt;code&gt;BezierInfo-2&lt;/code&gt; dev repo to the main &lt;code&gt;bezierinfo&lt;/code&gt; repo, which feels sensible: you don't want to indiscriminately push your dev code to prod without review.&lt;/p&gt;
&lt;p&gt;But this sure makes an involved process a heck of a lot easier.&lt;/p&gt;
&lt;p&gt;I guess that means I should also add a Github action to automatically build the ToC for this blog site anytime I add a new entry... because that's also a manual step right now... and I can probably offload the RSS generation rather than doing that in-browser every time.&lt;/p&gt;
</description>
<category>Bezier</category>
<category>Github</category>
<category>Automation</category>
<link>http://pomax.github.io/#gh-weblog-1591576580138</link>
<guid>http://pomax.github.io/#gh-weblog-1591576580138</guid>
<pubDate>Mon, 08 Jun 2020 00:36:20 GMT</pubDate>
</item>
<item>
<title> Fixing Windows 10's "error code 19"</title>
<description>&lt;p&gt;In a bizarre happenstance, I rebooted my Windows 10 workstation after doing nothing special in particular, and all my USB devices stopped working. Or rather, they worked fine, until Windows 10 got control of the system.  Not having a keyboard or mouse, I had to remote into my workstation from a different computer, but that revealed that for some reason, the "Intel USB 3.0 eXtensible Host Controller Driver" didn't work. And not because the driver was bad, but because a registry setting was wrong:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"Windows cannot start this hardware device because its configuration information (in the registry) is incomplete or damaged. (Code 19)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now, if you Google for this error, you will get a million click-bait articles, and a handful of real posts that tell you to uninstall the device in Device Manager, and then reboot - and of course, that does nothing.&lt;/p&gt;
&lt;p&gt;Then some of them tell you to regedit your way to success by deleting the &lt;code&gt;LowerFilters&lt;/code&gt; and &lt;code&gt;UpperFilters&lt;/code&gt; keys in the HKEY_LOCAL_MACHINE &amp;gt;  System &amp;gt; CurrentControlSet &amp;gt; Control &amp;gt; Class &amp;gt; ... entry, which is invariable for CD-ROM or DVD drives, and that of course does nothing because those are not your problem.&lt;/p&gt;
&lt;p&gt;Instead, you need to open HKEY_LOCAL_MACHINE &amp;gt;  System &amp;gt; CurrentControlSet &amp;gt; Control &amp;gt; Class, and then simply step through the entries until you find the &lt;code&gt;USB&lt;/code&gt; entry. In my case, that was &lt;code&gt;{36fc9e60-c465-11cf-8056-444553540000}&lt;/code&gt; rather than one of the million &lt;code&gt;{4d36e9xx-e325-11ce-bfc1-xxxxxx}&lt;/code&gt; keys that people tell you to use.&lt;/p&gt;
&lt;p&gt;Look at the &lt;code&gt;LowerFilters&lt;/code&gt; and &lt;code&gt;UpperFilters&lt;/code&gt; values. Are there any? Delete them. Do they have the wrong case, like &lt;code&gt;UPPERFILTERS&lt;/code&gt;? Delete them. Just delete them. Then in Device manager, uninstall the host controller and then scan for new hardware.&lt;/p&gt;
&lt;p&gt;Presto, you fixed the problem.&lt;/p&gt;
&lt;p&gt;And I can only pray that you allowed Remote Desktop connections into your machine, because without that, it's going to be incredibly hard to solve this problem without buying a PS/2 keyboard and/or mouse.  "But I don't have a user password" I hear you say: fret not, &lt;a href="https://superuser.com/questions/106917/remote-desktop-without-a-password"&gt;there's a policy edit&lt;/a&gt; for that. "But I have Windows 10 Home Edition" I hear you say...  well then I got nothing for you. I don't even know why that version exists. Upgrade to Pro, then fix the problem, I guess.  And I really do, because I have no way of testing that.&lt;/p&gt;
&lt;p&gt;If you use Windows and you're reading this, you should be on Pro. In both senses of the word "should".&lt;/p&gt;
</description>
<category>Windows</category>
<category>Error</category>
<category>Code 19</category>
<category>RegEdit</category>
<category>USB</category>
<link>http://pomax.github.io/#gh-weblog-1586905169363</link>
<guid>http://pomax.github.io/#gh-weblog-1586905169363</guid>
<pubDate>Tue, 14 Apr 2020 22:59:29 GMT</pubDate>
</item>
<item>
<title> Speeding up Lightroom catalog work by not using Lightroom</title>
<description>&lt;p&gt;&lt;a href="https://www.adobe.com/products/photoshop-lightroom-classic.html"&gt;Adobe Lightroom&lt;/a&gt; catalogs are &lt;a href="https://sqlite.org/index.html"&gt;SQLite3&lt;/a&gt; files (just with the &lt;code&gt;.lrcat&lt;/code&gt; extension rather than the typical &lt;code&gt;.sqlite&lt;/code&gt; or &lt;code&gt;.db&lt;/code&gt; extensions) and some things that take Lightroom effectively forever can be performed in milliseconds if you're willing to ignore Lightroom entirely and just load the catalog in SQLite3, probably using &lt;a href="https://sqlitebrowser.org"&gt;an administrative GUI&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For instance, if you want the list of all filenames for images that haven't been tagged yet, good luck making Lightroom do that. Even with the &lt;a href="http://lightroomsolutions.com/a-quick-list-of-filenames/"&gt;user script that some people will tell you to use&lt;/a&gt;, actually getting Lightroom to perform this for even a low number of photos in a several thousand photo catalog will take excruciatingly long, whereas the SQLite3 query will probably take less than a second:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT
  originalFilename as filename
FROM
  Adobe_images as i,
  AgLibraryFile as f
WHERE
  i.rootFile = f.id_local
AND
  i.id_local NOT IN (
    SELECT DISTINCT(image) as id_local
    FROM AgLibraryKeywordImage
  )
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Load your catalog, run that query, and done.&lt;/p&gt;
&lt;p&gt;There is in fact a lot more that you can do this way, but you might need to do some table hunting: my lightroom catalog has 112 tables, and finding which table houses what information is "half the fun" (read: quite the chore). However, once you've found where to find what, writing a query that just pulls the data you need in exactly the format you need takes very little time, and the amount of time you save for subsequent occasions you need to do the same thing is incredible.&lt;/p&gt;
&lt;p&gt;Best of all, you can automate your sqlite. Python, Node, Ruby, all common modern scripting languages can with a sqlite connector, so you can just write a script that loads in the catalog file, runs your query, writes the result to file (or even updates the catalog directly) and all you have to do is execute your script.  And really, that's what we wish Adobe just offered out of the box.&lt;/p&gt;
&lt;p&gt;They don't, but because they use Sqlite3, "they do".&lt;/p&gt;
</description>
<category>Adobe</category>
<category>Lightroom</category>
<category>SQLite</category>
<category>SQLite3</category>
<link>http://pomax.github.io/#gh-weblog-1568672424870</link>
<guid>http://pomax.github.io/#gh-weblog-1568672424870</guid>
<pubDate>Mon, 16 Sep 2019 22:20:24 GMT</pubDate>
</item>
<item>
<title>Using filters with your Lumix G Vario 7-14mm aspherical lens</title>
<description>&lt;p&gt;I own a &lt;a href="https://www.dpreview.com/reviews/panasonic-lumix-dc-gh5"&gt;Panasonic Lumix GH5&lt;/a&gt;, and it's pretty great, and I also own the &lt;a href="https://www.dpreview.com/reviews/panasonic-7-14-4-o20"&gt;Panasonic Lumix Vario G 7-14mm aspherical lens&lt;/a&gt; and it's &lt;em&gt;also&lt;/em&gt; pretty great, except for one problem: you can't put filters on it. It has a ridiculous integrated sun hood without any sort of screwthread so you can't screw in even a clear filter to protect the lens, and I don't mean "from being dropped" but even from something simple like a bit of water spray hitting the lens glass and being a chore to clean off because the lens is a glass dome instead of an easy to clean sheet.&lt;/p&gt;
&lt;p&gt;I had a look around at filter adapters and they're either &lt;a href="https://www.amazon.com/Wonderpana-System-Olympus-7-14mm-Thirds/dp/B00AUK8XNG"&gt;very expensive&lt;/a&gt;, or &lt;a href="https://www.newsshooter.com/2014/05/05/dfocus-filter-adapter-for-panasonic-lumix-7-14-f4-0-designed-for-blackmagic-pocket-cinema-camera-users/"&gt;simply non-existent&lt;/a&gt;, so I've been trying to figure out something that works without breaking the bank or custom fabrication. I initially thought of using the lens cap that comes with the lens, trimming off the "cap" side with a band saw, and then gluing a filter ring onto it so that I can screw in a filter, but as it turns out: you don't even need to do that.&lt;/p&gt;
&lt;p&gt;The sun hood &lt;em&gt;just barely&lt;/em&gt; fits in a 72mm step up ring, fitting pretty tight, and while 72-82mm is not big enough of a step (you'll see the edges of the ring at 7mm), using a 72-86mm step ring works splendidly, without anything in the frame even at 7mm. So: rather than buying a $100+ solution so you can then mount unaffordable and hard to find 105mm filters to your lens, I would strongly recommend first trying the following $15 solution, instead (and if it doesn't work for you, at least you've only spent $15):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;get a &lt;a href="https://www.amazon.com/gp/product/B009T1C1IU"&gt;72-86mm filter step-up ring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;get an &lt;a href="https://www.amazon.ca/gp/product/B07HJ98MCG"&gt;86mm thin UV filter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;you're done.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Well, almost: that sun hood isn't round, it's got some cutouts, so you probably want to put a strip of "something" to cover up those holes so light can't get in from behind, reflect off the rear of the filter glass, and make its way into your shot. It's artsy, but probably not what you're going for.&lt;/p&gt;
&lt;p&gt;(You might be tempted to cut your lens cap for that, but I'd recommend against that: the cap works on the same principle of "wedging itself over the sun hood" so with the lens cap barrel over the sun hood, the lips of the sun hood will no longer have any spring, and can't grip the step-up ring)&lt;/p&gt;
&lt;h3 id="a-short-picture-tutorial"&gt;A short picture tutorial&lt;/h3&gt;
&lt;p&gt;Step 1: get your parts ready!&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/7-14mm filter/parts.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Step 2: place your step-up ring 86mm down, 72mm up, and press your lens down all the way through.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/7-14mm filter/base.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Step 3: screw on your filter...&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/7-14mm filter/filter.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Step 4: you're basically done.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/7-14mm filter/done.jpg"&gt;&lt;/p&gt;
</description>
<category>Photography</category>
<category>Panasonic</category>
<category>Lumix</category>
<category>Vario</category>
<category>7mm</category>
<category>14mm</category>
<category>7-14mm</category>
<category>Lens</category>
<category>Filter</category>
<link>http://pomax.github.io/#gh-weblog-1553009656840</link>
<guid>http://pomax.github.io/#gh-weblog-1553009656840</guid>
<pubDate>Tue, 19 Mar 2019 15:34:16 GMT</pubDate>
</item>
<item>
<title> Adventures in HDMI land</title>
<description>&lt;p&gt;I like to cook, and I like to record the process, although I haven't been doing this nearly enough as I should. We moved, I got some new camera gear, before you know it, it's a year later. It happens.&lt;/p&gt;
&lt;p&gt;But, our new place has a fairly decent kitchen, and I'd like to record my prep and stove work, and so I wanted a setup where I could just stream when I was doing random cooking, while also recording when doing interesting dishes, and that poses a problem because the "prep stations" (two kitchen islands, one wood surfaced, one stainless/markble) are a good 3 meters away from the stove and range, and rolling a tripod with led panels and an HD recorder on it is fairly cumbersome. Especially since the prep stations need the lighting, whereas the stove/range already have plenty of decent light.&lt;/p&gt;
&lt;p&gt;So I figured I'd get a nice long HDMI cable, and only move the camera around. &lt;/p&gt;
&lt;p&gt;But this poses a problem.&lt;/p&gt;
&lt;h3 id="what-kind-of-hdmi-cable-do-we-need-"&gt;What kind of HDMI cable do we need?&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.hdmi.org/"&gt;HDMI&lt;/a&gt; is not one thing, there's a few standards, notably HDMI 1.4, HDMI 2.0, HDMI 2.0a, HDMI 2.0b, and HDMI 2.1, and their main differentiator is "bandwidth". That is: the amount of data per second you can push from one device to another device. "1080p", "3d", "dts audio", "ethernet", these are all fancy functions that only work if there's sufficient bandwidth.&lt;/p&gt;
&lt;p&gt;In fact, looking at a &lt;a href="https://en.wikipedia.org/wiki/HDMI#Main_specifications"&gt;comprehensive table of HDMI version&lt;/a&gt;, there's some interesting things going on: HDMI 1.* never makes it over 10 gigabits per second, whereas HDMI 2.0 can do 14 gbps, and HDMI 2.1 can do 42 gbps.&lt;/p&gt;
&lt;p&gt;But wait, there's more! Cables aren't perfect, and the longer the cable, the more signal degradation you get, to the point where individual frames (or even long sequences of frames) can get corrupted beyond the decoder's ability to fix, at which point you get black frames. Which is the opposite of what you want.&lt;/p&gt;
&lt;p&gt;So, what are some usable cable lengths? Well, that depends: what is the cable made of, and what method was it assembled in?&lt;/p&gt;
&lt;p&gt;Different cables use different materials and construction methods, and &lt;a href="https://en.wikipedia.org/wiki/Signal_reflection"&gt;signal reflection&lt;/a&gt; becomes a problem sooner or later depending on the quality of material and methods used.&lt;/p&gt;
&lt;p&gt;The highest quality copper "high speed" HDMI cables, capable of 18/14gbps, can theoretically reach 10 meters but in practice they almost never do. Of course, if you don't &lt;em&gt;need&lt;/em&gt; the maximum bandwidth, you can easily get a high quality 30 meter cable and be fine: 1080p from some video source to an HDMI projector, for instance, is absolutely no problem if you're using an HDMI 2.0 high speed cable. If you need a 4k signal, though, things get trickier.&lt;/p&gt;
&lt;h3 id="let-s-jump-into-chroma-subsampling-"&gt;Let's jump into Chroma subsampling!&lt;/h3&gt;
&lt;p&gt;Not only is 4k video four times as much data as 1080p video, but the higher resolution typically also comes with higher bit depth and more complex &lt;a href="https://en.wikipedia.org/wiki/Chroma_subsampling"&gt;"chroma subsampling"&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you're used to RGB pixels, where each pixel encodes its colour &lt;em&gt;and&lt;/em&gt; brightness at the same time, then chroma subsampling will probably be a new idea to you: instead of "full data", pixels are encoded in blocks of (typically) 2 rows of 4 pixels each, and while each pixel has its own brightness encoded, colour information gets applied to multiple pixels at a time, so you could have a set of eight pixels:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p1 p2   p3 p4
p5 p6   p7 p8
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;with unique brightness information per pixel:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;b1 b2   b3 b4
b5 b6   b7 b8
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;but with colour information applied to blocks of multiple pixels:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; c1  (c1)   c2  (c2)
(c1) (c1)  (c2) (c2)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So in the above example: eight pixels, but the left four are "different shades of &lt;code&gt;c1&lt;/code&gt;" and the right four are "different shades of &lt;code&gt;c2&lt;/code&gt;". This reduces the bandwidth needed to transmit the data, at the expense of losing some of the information compared to true raw video footage.&lt;/p&gt;
&lt;p&gt;There are &lt;a href="https://en.wikipedia.org/wiki/Chroma_subsampling#Sampling_systems_and_ratios"&gt;a few standard schemes&lt;/a&gt; for chroma subsampling, with &lt;code&gt;4:4:4&lt;/code&gt; being "raw video": &lt;strong&gt;4&lt;/strong&gt; columns of 2, where the first row has &lt;strong&gt;4&lt;/strong&gt; unique values, and the second row has an &lt;em&gt;additional&lt;/em&gt; &lt;strong&gt;4&lt;/strong&gt; unique values, and every other &lt;code&gt;4:x:y&lt;/code&gt; value being subsampled.&lt;/p&gt;
&lt;p&gt;And of course, the more unique values that are supported by the subsampling scheme, the more data we have that needs to be transmitted, and the more bandwidth a cable needs to have to support the signal. And the faster signal reflection will become a problem.&lt;/p&gt;
&lt;h3 id="how-many-bits-are-you-using-"&gt;How many bits are you using?&lt;/h3&gt;
&lt;p&gt;Of course, chroma subsampling only gives you part of the information needed to figure out your bandwidth needs: we also need to know how many bits are used for the brightness and colour values. Much like digital photography, digital videography has a few options.&lt;/p&gt;
&lt;p&gt;The classic value for simple video is 8 bits. A simple &lt;code&gt;[0,255]&lt;/code&gt; range that works well for traditional computer graphics because regular monitors are (even today) typically 8 bit per colour channel. However, video doesn't get shot purely for typical computer monitors, and -as with digital photography- the fewer the bits, the less dynamic range, and dynamic range makes just as big a difference for video as it does for photography. So most video cameras can do 10 bits, and expensive video cameras can do 12, 14, or even 16 bits.&lt;/p&gt;
&lt;h3 id="oh-yeah-which-frame-rate-are-you-shooting-at-"&gt;Oh yeah, which frame rate are you shooting at?&lt;/h3&gt;
&lt;p&gt;Finally, the last thing that matters is how many frames of video data you're generating per second. Obviously, a 60 fps data stream is going need twice as much bandwidth as a 30 fps data stream. You might even shoot at 60 fps despite your final video using 24 fps, purely so you have more data available to work with during editing.&lt;/p&gt;
&lt;h3 id="back-to-hdmi-cables-"&gt;Back to HDMI cables!&lt;/h3&gt;
&lt;p&gt;And now we have everything we need to know to understand the limits of HDMI cables. The HDMI 2.0 standard defines a maximum bandwidth of 18.2 gigabits per second, so let's do some maths. A raw 4k frame constitutes 8.3 megapixels, which at 10 bit &lt;code&gt;4:4:4&lt;/code&gt; ("true", "raw", or "not subsampled"), would require 30 * 8.3 = 250 megabits per frame, which at 60 frames per second means we need 15 gigabits per second of bandwidth.&lt;/p&gt;
&lt;p&gt;And if we look back at the maximum data rate for HDMI 2.0, we don't get 15Gbps. We only get 14.4... so that could be a problem. In fact, video also usually has sound in addition to picture, so we now have negative bandwidth left to also add in audio. That really is a problem!&lt;/p&gt;
&lt;p&gt;Of course, most devices don't send out raw data, they apply at least &lt;em&gt;some&lt;/em&gt; kind of compression, and the same is true for HDMI video: rather than sending all the raw data, an HDMI video stream is typically encoded as &lt;a href="https://en.wikipedia.org/wiki/QuickTime_File_Format"&gt;&lt;code&gt;.mov&lt;/code&gt;&lt;/a&gt; or &lt;a href="https://en.wikipedia.org/wiki/MPEG-4_Part_14"&gt;&lt;code&gt;.mp4&lt;/code&gt;&lt;/a&gt;, with data compressed either as &lt;a href="https://en.wikipedia.org/wiki/Group_of_pictures"&gt;"long GOP"&lt;/a&gt;, blocks of frames (storing 1 real frame, and then a collection of "differences from one frame to the next", super handy for fixed camera shots with a fair amount of scene content that hardly changes over time), or as &lt;a href="https://en.wikipedia.org/wiki/Intra-frame_coding"&gt;"all-intra"&lt;/a&gt;, consisting of individual frames (useful when the camera moves and every single pixel will have a different value from frame to frame). So what we end up with is &lt;em&gt;quite a lot of parameters&lt;/em&gt; that all work together to determine whether or not your HDMI signal is going to make it from one end of the cable to the other end of the cable in one piece.&lt;/p&gt;
&lt;h3 id="back-to-the-kitchen-"&gt;Back to the kitchen!&lt;/h3&gt;
&lt;p&gt;So what &lt;em&gt;are&lt;/em&gt; my parameters? First off, my camera is a &lt;a href="https://www.panasonic.com/uk/consumer/cameras-camcorders/lumix-g-compact-system-cameras/dc-gh5l.specs.html"&gt;Panasonic Lumix GH5&lt;/a&gt;, capable of sending out 10 bit 4k video, with &lt;code&gt;4:2:2&lt;/code&gt; subsampling, at 60 fps, &lt;em&gt;as long as it doesn't also have to record that&lt;/em&gt;, which means it can either &lt;em&gt;send&lt;/em&gt; 10 bit &lt;code&gt;4:2:2&lt;/code&gt;, or &lt;em&gt;record&lt;/em&gt; 10 bit &lt;code&gt;4:2:0&lt;/code&gt;. It does not have the processing power to both read out a 10 bit &lt;code&gt;4:2:2&lt;/code&gt; video signal &lt;em&gt;and&lt;/em&gt; internally encode that to an SD card at the same time.&lt;/p&gt;
&lt;p&gt;(Could they have put a better cpu in the camera to make it able to do that anyway? Yep. Would it burn out because the camera would overheat in minutes? Absolutely. Consumer cameras aren't exactly designed for with good cpu cooling in mind. Fun fact: commercial digital video cameras super duper are)&lt;/p&gt;
&lt;p&gt;But that's okay, because SD cards are tiny, and 4k video file are huge, so instead of relying on the camera to save the video stream it's generating, I have an &lt;a href="https://www.atomos.com/ninja-inferno"&gt;Atomos Ninja Inferno&lt;/a&gt;, which is an external HDMI recorder capable of ingesting 4k, 10 bit &lt;code&gt;4:4:4&lt;/code&gt; video at 60fps, and write that to an SSD.&lt;/p&gt;
&lt;p&gt;Of course, the SSD needs to be &lt;em&gt;fast&lt;/em&gt; because while video isn't saved to file at 18gbps, it still needs a bloody fast drive to keep up with a high quality codec like ProRes, which uses about 1gbps for 10 bit &lt;code&gt;4:2:2&lt;/code&gt; "medium quality" video. And the SSD needs to be &lt;em&gt;capacious&lt;/em&gt; because at that data rate, a minute of footage takes up 8.8 gigabytes of space. &lt;/p&gt;
&lt;p&gt;That's right, a 1TB SSD will hold about two hours of ProRes-medium video, roughly the length of a single film these days. You thought we finally lived in an era where you could fit hundreds of films on a single 1 terabyte harddisk? Not when you're &lt;em&gt;recording&lt;/em&gt; those films!&lt;/p&gt;
&lt;p&gt;So, I have a camera spitting out 10 bit &lt;code&gt;4:2:2&lt;/code&gt; 60 fps 4k video, and a recorder capable of ingesting 10 bit &lt;code&gt;4:2:2&lt;/code&gt; 60 fps 4k. How long a cable can I put between those two?&lt;/p&gt;
&lt;h3 id="copper-cables"&gt;Copper cables&lt;/h3&gt;
&lt;p&gt;While HDMI 2.0-rated copper cables will happily do a 1080p signal over 30 feet or more, pushing the limit of what the cable can carry in terms of bandwidth severely limits how long a cable can get. Even a high quality cable will only do about 80 inches, 2 meters, of reliable signal. After that, frames start to drop, with intermittent signal deterioration past the point of being decodable, and while you might not notice that if your "recorder" is a TV, if it's a real recorder, those dropped frames are both unwanted, and very obvious. Imagine in your TV turned itself off every time a single frame dropped, and you can imagine the effect you get when frames drop for recording equipment.&lt;/p&gt;
&lt;p&gt;You can, however, improve this cable length by using a "powered HDMI cable", which is similar to a powered USB cable in that it takes the incoming signal, boosts it to something so strong that it can survive unattenuated for a longer distance, and then sends that signal instead. These cables have their own power supply (yep: cables with power supplies) and can certainly bridge lengths of 10 meters, but they're really bulky, and as such really only good for equipment that isn't going to be moved around much. Plus you'll need to have a power cable that is long enough, too.&lt;/p&gt;
&lt;p&gt;So: not super great for single-cameras setups.&lt;/p&gt;
&lt;p&gt;There are some alternatives, of course: there are &lt;a href="https://www.newegg.com/Product/Product.aspx?Item=9SIA6ZP8E36502"&gt;HDMI-to-ethernet&lt;/a&gt; and &lt;a href="https://www.blackmagicdesign.com/products/miniconverters"&gt;HDMI-to-SDI&lt;/a&gt; converters, where you run a (very) short high quality HDMI cable from your source to the converter, which then sends the signal on either over one or more &lt;a href="https://en.wikipedia.org/wiki/Category_6_cable"&gt;ethernet&lt;/a&gt; cables, or over &lt;a href="https://en.wikipedia.org/wiki/Serial_digital_interface"&gt;SDI cable&lt;/a&gt;, going into a converter back to HDMI at whatever destination you need to signal to get to. But those adapters also require power, and they're bulky, and so again, that's not going to work if you have a single camera that you need to move around.&lt;/p&gt;
&lt;p&gt;What does that leave?&lt;/p&gt;
&lt;h3 id="fiber-optic-cables"&gt;Fiber optic cables&lt;/h3&gt;
&lt;p&gt;If you were entertaining the idea of dropping $200 on ethernet converters anyway, you now also have the option to instead buy a $200 HDMI cable. Which sounds like an insane amount of money, but we're not talking about regular cables, we're talking about glass.&lt;/p&gt;
&lt;p&gt;Fiber optic HDMI cables have very-low-power converters in their plugs that convert electricity to optical signals, and then send light from one end of the cable to the other end, over distances that copper could never do, all the way up to 100 meters without needing external power.&lt;/p&gt;
&lt;p&gt;That's amazing! &lt;/p&gt;
&lt;p&gt;Obviously I bought one!&lt;/p&gt;
&lt;p&gt;...except fiber optic cables have a different problem: they're made of glass, and so they're fragile. Not "blow at them wrong and they break" fragile, but "transport them in a bouncy truck without enough padding and they will definitely stop working" fragile. And guess what happens when you order cables online? Which you'll have to do, because no local shop is going to carry $200 cables?&lt;/p&gt;
&lt;h3 id="adventures-in-hdmi-cable-ordering-"&gt;Adventures in HDMI cable ordering!&lt;/h3&gt;
&lt;p&gt;So yeah, I ordered one online, and by the time it got to my house it was thoroughly busted. If you like the flickering of a poorly wired lamp, imagine that, but then for video feeds. So I had to send it back and get a replacement.&lt;/p&gt;
&lt;p&gt;Which was also busted, flickering only marginally less.&lt;/p&gt;
&lt;p&gt;So I actually talked to the folks at Atomos who admitted that they, too, have to order a high number of them in the hopes of getting at least one that happened to work, so... that's what I did: I ended up ordering four cables, of which two were busted and two worked, so I kept one and sent the other three back.&lt;/p&gt;
&lt;p&gt;You might wonder how the people who make these cables even make any money, but remember that we're basically pushing the limit of what an HDMI cable can carry: all the cables that were busted for 10 bit &lt;code&gt;4:2:2&lt;/code&gt; 4k video at 60 fps worked &lt;em&gt;perfectly fine&lt;/em&gt; for 10 bit &lt;code&gt;4:2:2&lt;/code&gt; 4k video at 30 fps, as well as 8 bit &lt;code&gt;4:4:4&lt;/code&gt; 4k video at 60 fps, so people who order these cables may literally never discover their cable's damaged. Only folks who really need them for the upper limit of what HDMI 2 cables can carry will notice.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Hurray, that's me.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id="in-conclusion"&gt;In conclusion&lt;/h3&gt;
&lt;p&gt;HDMI is weird. On the one hand it's super useful and the spec is ever improving, but on the other cable manufacturers are not interested in making cables that actually support HDMI at max settings, and so if you need anything beyond a regular length cable, you're going to be in for a ride. &lt;/p&gt;
&lt;p&gt;HDMI 2.1 is out, it has more than twice the bandwidth of HDMI 2.0, at 48 gbps, but no one's making HDMI 2.1 cables yet. There's a Chinese company that claims to make them, but they're so incredibly fat (even though they're fiber optic) that you can't connect one to a camera without the weight of the cable off the ground either snapping the connector on a side connection, or just falling out from a bottom connection. &lt;/p&gt;
&lt;p&gt;So, if you need a long cable: order many of them. Ordering a single cable at a time is guaranteed to give you a broken cable (for your needs) and you'll just end up in an endless cycle of filing for refunds or replacements. Save up, order four (or more) in one go and then keep one that works and send the rest back either as defective, or as over-stocked. Maybe one day cable manufacturers will change their packaging and fiber optic cables will be safe to ship individually, but that day is not today, and I don't expect it to come any time soon.&lt;/p&gt;
&lt;h3 id="so-wait-which-did-you-get-"&gt;So wait, which did you get?&lt;/h3&gt;
&lt;p&gt;I got this one: the &lt;a href="https://www.amazon.ca/gp/product/B06XS8T2W4"&gt;Monoprice SlimRun AV HDR High Speed Cable for HDMI-Enabled Devices, 18Gbps, Fiber Optic, AOC, YUV &lt;code&gt;4:4:4&lt;/code&gt;, 50ft, Black&lt;/a&gt; and when it works, it's lovely. It's light, its stable, I can carry the camera all around the kitchen or mount it on the prep station tripod or the range camera boom in seconds. &lt;/p&gt;
&lt;p&gt;But again, if you're thinking of getting a cable like this:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;order many more than you need, and send the ones you can't use back.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;And then when you have a working cable: have fun!&lt;/p&gt;
</description>
<category>Photo</category>
<category>Video</category>
<category>HDMI</category>
<link>http://pomax.github.io/#gh-weblog-1544994322697</link>
<guid>http://pomax.github.io/#gh-weblog-1544994322697</guid>
<pubDate>Sun, 16 Dec 2018 21:05:22 GMT</pubDate>
</item>
<item>
<title> Listening to birds... from inside the house!</title>
<description>&lt;p&gt;We moved to a house on Vancouver Island not too long ago, to a fairly quiet area that's just outside a city, with lots of birdsong going on all day, every day. However, it's January and it's pretty cold out so while birdsong is lovely to listen to, opening a window isn't really an option.&lt;/p&gt;
&lt;p&gt;What is a couple of tech-minded people to do in a situation like this?&lt;/p&gt;
&lt;h2 id="-let-s-add-in-all-the-tech-"&gt;"Let's add in *all* the tech"&lt;/h2&gt;
&lt;p&gt;We ended up setting up an XLR conference microphone (the kind that needs 48V &lt;a href="https://en.wikipedia.org/wiki/Phantom_power"&gt;phantom power&lt;/a&gt; to work) outside, with a long (like, looong) cable running down the side, under the porch, into the house through a ventilation box, into the living room, and into a USB XLR mixer (a Behringer &lt;a href="https://www.long-mcquade.com/67988/Pro_Audio_Recording/Audio_Interfaces/Behringer/U-Phoria_UMC404HD_Audiophile_4x4_24-Bit_192_kHz_USB_Audio_MIDI_Interface.htm"&gt;U-Phoria UMC404HD&lt;/a&gt;), and then using DDMF's &lt;a href="http://www.virtualaudiostream.com"&gt;Virtual Audio Stream&lt;/a&gt; to set up a digital audio filter chain from the microphone input to the speakers, using their "Effect Rack" utility.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/bird-vst/the-setup.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Now we can listen to birds (oh my god, so many birds) while working inside! (at least until the weather improves and we can open the windows like normal people would =)&lt;/p&gt;
&lt;h2 id="the-filter-chain"&gt;The filter chain&lt;/h2&gt;
&lt;p&gt;The following image shows the filter chain we're using in Effect Rack:&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/bird-vst/ddmf-filter-chain.png" alt=""&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First, a high-pass filter to cut out definitely-not-related-to-birdsong low frequencies.&lt;/li&gt;
&lt;li&gt;Then, an automatic noise reduction filter. This does a relative good job are removing unwanted noise, but not quite enough.&lt;/li&gt;
&lt;li&gt;That's followed by a multi-band compressor, which is used to further cut out any frequencies after noise reduction that are definitely not in the range of bird song.&lt;/li&gt;
&lt;li&gt;This is followed by a second single-pass compressor that aggressively dampens any sound that's louder than nearby birdsong, such as cars driving by close to the mic, or someone using a chainsaw the next field over.&lt;/li&gt;
&lt;li&gt;Finally, there's an equaliser that's being used as an aggressive high frequency cut off, throwing away everything that's above 10KHz&lt;/li&gt;
&lt;li&gt;There's also a little spectrum analyzer, which helps to tune the previous filters, since it's pretty obvious which frequencies bird song is happening at.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You may have noticed that only the right channel seems to be hooked up, except all the way at the end: this is because the microphone only generates a single channel, it's not a stereo microphone, and so all the processing really only needs to happen to the one channel. However, because it's nice to have the audio come out of both speakers, all the way at the end "all channels" are sent to "all speakers")&lt;/p&gt;
&lt;p&gt;So, in case you're curious, let's look at each filter in detail.&lt;/p&gt;
&lt;h2 id="cutting-out-the-low-frequencies-"&gt;Cutting out the low frequencies.&lt;/h2&gt;
&lt;p&gt;The initial high pass filter (a signal processing term for "thing that lets frequencies above X through, while setting the volume for frequencies below X to zero) is an instance of &lt;a href="https://www.meldaproduction.com/MBandPass"&gt;Melda Production's MBandPass&lt;/a&gt; filter, set pretty aggressively. &lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/bird-vst/bandpass.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Everything under 224Hz gets thrown away, using a 12dB knee, with insanely low quantization. This actually does a great job at removing most car noise without affecting the rest of the audio too much. &lt;/p&gt;
&lt;h2 id="removing-line-and-signal-noise-"&gt;Removing line and signal noise.&lt;/h2&gt;
&lt;p&gt;To remove general noise, both because the outside world is noisy, and because there's a long cable on the mic, I'm using &lt;a href="https://acondigital.com/products/restoration-suite"&gt;Acon's noise reduction filter&lt;/a&gt; with a 1.83 second sliding window, meaning that it looks at 1.82 seconds of audio that's come by, tries to find the "noise profile" in that, and then applies it to the current signal.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/bird-vst/noise-reduction.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;While this is almost guaranteed to always be "wrong", it's long enough to get a decent noise profile, while being short enough to still remove &lt;em&gt;most&lt;/em&gt; noise from the audio signal.  &lt;/p&gt;
&lt;h2 id="cutting-out-these-are-not-birds-sounds-"&gt;Cutting out "these are not birds!" sounds.&lt;/h2&gt;
&lt;p&gt;Birdsong is doesn't use a lot of low frequencies, so in order to further weed out any frequencies that we don't actually want to be listening to, I use &lt;a href="https://www.image-line.com/plugins/Effects/Maximus"&gt;Image-Line's "Maximus" multi-band compressor&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A compressor is a thing that can take an incoming audio signal, look at the volume-per-frequency range, and then change that range. The most common use is to reduce the volume on really loud noises, so that if you talk into a mic it does nothing, but if you yell into the mic, the volume doesn't suddenly blow out your speakers - that's not how it's being used here.&lt;/p&gt;
&lt;p&gt;Instead, we're applying three different compressor settings to each of the low, mid, and high bands in the audio signal.   &lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/bird-vst/low-compressor.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;In the low band (0Hz-200Hz), we change the volume range [0,max] to the volume range [0,0]. We literally just throw &lt;em&gt;all&lt;/em&gt; of it away. The preceding high pass filter should have already taken care of that, but it doesn't hurt to make sure low frequencies stay gone.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/bird-vst/mid-compressor.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;In the mid band (200Hz-3KHz), we change the volume mapping so that anything that's loud, stays loud, but anything that's soft is pretty much scaled waaaay back down. To zero, in fact, for most volumes. Or somewhere progressively closer to the original level on the high end of the spectrum's "mid" band. &lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/bird-vst/high-compressor.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;In the high frequencies band (3KHz and up), which is where most bird song is found, we don't really do much: this is a typical compressor function that just makes sure that things that are too loud to be reasonable get scaled down in volume. In case a bird yells right next to the microphone, mostly.&lt;/p&gt;
&lt;p&gt;I'm looking at you, Stellar's Jays... =_=&lt;/p&gt;
&lt;h2 id="making-sure-a-sudden-car-or-chainsaw-doesn-t-give-us-a-heart-attack-"&gt;Making sure a sudden car or chainsaw doesn't give us a heart attack.&lt;/h2&gt;
&lt;p&gt;Even with all that compressor work, there's still the chance that cars, chainsaws, or people yelling end up generating very loud noises in the same range that bird song occurs in, so we add one more "overall" compressor. &lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/bird-vst/second-compressor.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;This is &lt;a href="https://www.meldaproduction.com/MCompressor"&gt;Melda Production's MCompressor&lt;/a&gt;, and its job is to simply take the overall signal, and dampen it when it's too loud.&lt;/p&gt;
&lt;h2 id="cleaning-up-any-compound-distortion-at-the-high-end-"&gt;Cleaning up any compound distortion at the high end.&lt;/h2&gt;
&lt;p&gt;You might be wondering about whether all those filters one after another don't generate some kind of artificial noise, and the answer is: oh no, they absolutely do. So to combat the noise that is most audible, I use an equaliser filter (&lt;a href="https://www.image-line.com/support/FLHelp/html/plugins/EQUO.htm"&gt;Image Line's EQUO&lt;/a&gt;) to pretty much throw away anything about 10KHz, with a gentle volume reduction starting at 2.5KHz, which does a nice job at throwing away the high frequency noise that previous filter chain generated.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/bird-vst/eq-cutoff.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;You might think "well why not use a low pass filter?" as that's essentially what this does, and the reason is mostly because I wanted a little more more control over the knee and ramp coming down from 2.5KHz which is exactly what an equalizer lets you do. &lt;/p&gt;
&lt;h2 id="and-that-s-it-all-that-s-left-is-to-enjoy-"&gt;And that's it. All that's left is to enjoy.&lt;/h2&gt;
&lt;p&gt;The last filter is &lt;a href="https://www.meldaproduction.com/MAnalyzer"&gt;Melda Production's "MAnalyzer"&lt;/a&gt;, which doesn't actually do anything to the audio signal (it just lets it pass through unchanged), but instead simply shows what's happening in terms of which frequencies are playing how loud on a moment-to-moment basis. This is very useful to see where unwanted frequencies are still coming through, to optimize any of the previous filters, plus... it looks pretty!&lt;/p&gt;
&lt;h2 id="so-what-does-it-sound-like-"&gt;So what does it sound like?&lt;/h2&gt;
&lt;p&gt;Of course, all this talk about bird song leads to the inevitable "okay, but... what does it sound like?". So here are two clips. One is the "raw audio" as simply captured by the mic outside straight from the XLR mixer, on a mildly rainy day - there's some birds twittering, a car drives by, it's mostly unimpressive but it's contrasted against the same audio after it's been run through the filter chain, representing what we hear in our home office through the speakers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://clyp.it/ksmbapw1?token=5fca3db27da4d26cfea827dbf5295608"&gt;the raw audio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://clyp.it/2hj4kmfc?token=b535e17e75cc3f535b75927cec1203d1"&gt;the filtered audio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'll leave you to decide which sounds better, and while you do, I'll be going back to enjoying our most excellent bird song!&lt;/p&gt;
&lt;p&gt;(And if you have cleanup recommendations, leave a comment! Tips and tricks are always welcome)&lt;/p&gt;
</description>
<category>Audio</category>
<category>VST</category>
<category>Birds</category>
<link>http://pomax.github.io/#gh-weblog-1517436884711</link>
<guid>http://pomax.github.io/#gh-weblog-1517436884711</guid>
<pubDate>Wed, 31 Jan 2018 22:14:44 GMT</pubDate>
</item>
<item>
<title> Creating VST/AU/etc audio plugins in 2017</title>
<description>&lt;p&gt;Probably the best tutorial on getting started writing a VST plugins (whether you want to make an instrument or a filter) is Martin Finke's &lt;a href="http://www.martin-finke.de/blog/tags/making_audio_plugins.html"&gt;Making Audio Plugins&lt;/a&gt;. It covers going from "zero to hero" but it has one downside: it was written in 2012, and using equivalent tools from 2017 leads to some issues when trying to get to a point where you can actually compile your plugin. Mind you, they're not big issues, but they're "big enough to frustrate people who would otherwise dive right in, losing them as they walk away to do something else instead".&lt;/p&gt;
&lt;p&gt;So, what can we do?&lt;/p&gt;
&lt;p&gt;First off, it's 2017 (coming up to 2018) and I'm going to assume you're using Windows mostly because that's what I'm using (because several audio production tools I use only exist for Windows. I also have a mac, yes I own Ableton, no I'm not covering using XCode in 2017 here. But if you want to do that work for me, I will be more than happy to add your findings to this blog post! (hit me up &lt;a href="https://github.com/pomax/pomax.github.io/issues"&gt;here&lt;/a&gt; to discuss that!).&lt;/p&gt;
&lt;h2 id="getting-the-right-tools"&gt;Getting the right tools&lt;/h2&gt;
&lt;p&gt;You're probably on Windows 10, so we want to install &lt;a href="https://www.visualstudio.com/downloads/"&gt;Visual Studio 2017 Community Edition&lt;/a&gt; with all the SDKs checked during the installation. That's pretty important. We need those SDKs.&lt;/p&gt;
&lt;h2 id="following-the-instructions"&gt;Following the instructions&lt;/h2&gt;
&lt;p&gt;While "Making Audio Plugins &lt;a href="http://www.martin-finke.de/blog/articles/audio-plugins-002-setting-up-wdl-ol/"&gt;part 2&lt;/a&gt;" covers most of it, once you've used python to create the directory with all the files for your first plugin, and you're loading the &lt;code&gt;.sln&lt;/code&gt; file in Visual C++, you're going to hit warnings and errors.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Don't worry, it's okay&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Accept the suggestion by VC++ to upgrade the project to the modern SDKs (which it will fail at, but again, that's okay), and then instead of trying to compile &lt;code&gt;MyFirstPlugin-app&lt;/code&gt;, first make sure the project and Visual C++ know that we're working on Windows 10.&lt;/p&gt;
&lt;h3 id="update-the-platform"&gt;Update the platform&lt;/h3&gt;
&lt;p&gt;Go to &lt;code&gt;Project&lt;/code&gt; and then &lt;code&gt;Properties&lt;/code&gt;, and in the "General" settings, change the platform tools from "Visual Studio 2017 - Windows XP (v...)" to just "Visual Studio 2017 (v...)", so that we're not trying to compile against anything Windows-XP-related.&lt;/p&gt;
&lt;p&gt;If you don't do this, you'll see errors like the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Warning    MSB8003
Could not find WindowsSdkDir_71A variable from the registry.
TargetFrameworkVersion or PlatformToolset may be set to an invalid version number.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Which, aside from being horribly poor grammar, is also a red herring: what this really mean is "the project is using an SDK that cannot be found", which is true: we're on Windows 10, we're using SDK version 141 (or perhaps by the time you read this, even higher), rather than version 71.&lt;/p&gt;
&lt;h3 id="update-your-include-path-probably"&gt;Update your include path, probably&lt;/h3&gt;
&lt;p&gt;If, after updating the platform tools, you try to compile and you get &lt;code&gt;missing windows.h&lt;/code&gt; and/or &lt;code&gt;missing winapifamily.h&lt;/code&gt; errors, then we need to manually intervene because Visual Studio did not pick the correct paths for including common headers.&lt;/p&gt;
&lt;p&gt;In the project properties, go to the "VC++ Directories" section, because we'll need to add two directories to the "Includes" path, which is probably already filled in as &lt;code&gt;$(VC_IncludePath);$(WindowsSDK_IncludePath);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We'll need to add the &lt;code&gt;\mu&lt;/code&gt; and &lt;code&gt;\shared&lt;/code&gt; directories for the Windows SDK that we're working with, which as of the date of this post is the Windows 10 Fall Creator Edition SDK version 10.0.16299.0, found (by default - if you changed your installation path then you should know what to do here) in:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\Program Files (x86)\Windows Kits\10\Include\10.0.16299.0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Given that location, we will need to add the following two paths to the include path in the project properties include path:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;C:\Program Files (x86)\Windows Kits\10\Include\10.0.16299.0\mu;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;C:\Program Files (x86)\Windows Kits\10\Include\10.0.16299.0\shared;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So we end up with the Include path string "$(VC_IncludePath);$(WindowsSDK_IncludePath);C:\Program Files (x86)\Windows Kits\10\Include\10.0.16299.0\mu;C:\Program Files (x86)\Windows Kits\10\Include\10.0.16299.0\shared;".&lt;/p&gt;
&lt;h3 id="retargeting-the-project-possibly"&gt;Retargeting the project, possibly&lt;/h3&gt;
&lt;p&gt;Finally, it's possible that trying to compile after these two steps still doesn't work. In that case, right-click on &lt;code&gt;MyFirstPlugin-app&lt;/code&gt; and choose "retarget projects". This will pop up a dialog that lets you pick the SDK version. Make sure to pick the &lt;code&gt;10.0.....&lt;/code&gt; version that matches what we used for the Platform Tools in the project properties, and accept that change.&lt;/p&gt;
&lt;h2 id="you-should-be-good-to-go-"&gt;You should be good to go!&lt;/h2&gt;
&lt;p&gt;Alright, now we can get back to that awesome tutorial and make some audio plugins. Select &lt;code&gt;MyFirstPlugin-app&lt;/code&gt;, hit F5 to start a compile, and "things should just work(tm)".&lt;/p&gt;
</description>
<category>Audio</category>
<category>VST</category>
<category>Programming</category>
<category>VC++</category>
<category>2017</category>
<link>http://pomax.github.io/#gh-weblog-1512169175433</link>
<guid>http://pomax.github.io/#gh-weblog-1512169175433</guid>
<pubDate>Fri, 01 Dec 2017 22:59:35 GMT</pubDate>
</item>
<item>
<title>A beer riddle</title>
<description>&lt;p&gt;Cold beer I promise, if but in name; pour me one for the difference to remain. Lakes of beer I pass in strain - what am I?&lt;/p&gt;
&lt;p&gt;&lt;span style="background: black; color: black"&gt;
My name spells cold yet warm I work, my job to offer beer a fork: swim along or cloud the flow. It is my job to tell it: "no". What am I?
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style="background: black; color: black"&gt;
Once in water, I now swim here, holding that which muddles beer. Separate it from what is dear, thrown away once beer is clear. What am I?
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And the answer:&lt;/p&gt;
&lt;p&gt;&lt;span style="background: black; color: black"&gt;
From fish we get a jellied web, that filters the last bits of drab, from finished beers sent off for casking: "&lt;a style="color: black" href="https://en.wikipedia.org/wiki/Isinglass"&gt;isinglass&lt;/a&gt;" the name of asking.
&lt;/span&gt;&lt;/p&gt;
</description>

<link>http://pomax.github.io/#gh-weblog-1490481349209</link>
<guid>http://pomax.github.io/#gh-weblog-1490481349209</guid>
<pubDate>Sat, 25 Mar 2017 22:35:49 GMT</pubDate>
</item></channel>
</rss>

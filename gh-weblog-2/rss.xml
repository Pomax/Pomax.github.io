<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<atom:link href="http://pomax.github.io/gh-weblog-2/rss.xml" rel="self" type="application/rss+xml" />
<title>Pomax.github.io</title>
<description>My blog on github</description>
<link>http://pomax.github.io</link>
<lastBuildDate>Fri, 29 Sep 2023 17:31:58 GMT</lastBuildDate>
<pubDate>Fri, 29 Sep 2023 17:31:58 GMT</pubDate>
<ttl>1440</ttl>
<item>
<title> Writing a Node package using Rust... on Windows</title>
<description>&lt;p&gt;Let me preface this by saying that every single person who thinks that mingw or msys are valid excuses for not targeting true windows is actively making life worse for large swathes of developers. You're not helping. Windows applications and libraries should work on Windows, using the Windows platform.&lt;/p&gt;
&lt;p&gt;With that out of the way, let's write some code in Rust that we can call from Node.js so that we get the best of both worlds: the ease of development of Node.js, with the "I need this to be fast" parts handled by natively compiled code.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/llvm/llvm-project/releases/ because you'll need LLD (click &amp;quot;show all ... assets&amp;quot; and download the windows version"&gt;install LLVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.rust-lang.org/tools/install"&gt;install Rust&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;check to see if you have a &lt;code&gt;C:\Users\yournamehere\.cargo\config&lt;/code&gt; file, and if not, create one.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Open the cargo config file, and add the following to it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[target.x86_64-pc-windows-msvc]
linker = "lld-link.exe"
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Rust now knows that it's building for the Windows platform. Beauty.&lt;/p&gt;
&lt;p&gt;Next up, we'll need Node.js&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;install &lt;a href="https://github.com/coreybutler/nvm-windows"&gt;nvm-windows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;run &lt;code&gt;nvm install lts&lt;/code&gt; to install the current &lt;a href="https://en.wikipedia.org/wiki/Long-term_support"&gt;LTS&lt;/a&gt; version of Node&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And we're good to go. Let's start by creating a new project by running &lt;code&gt;cargo new testlib&lt;/code&gt; and then changing a few things because we want Rust to build us a library, not an executable:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;rename &lt;code&gt;src/main.rs&lt;/code&gt; to &lt;code&gt;src/lib.rs&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;add a section called &lt;code&gt;[lib]&lt;/code&gt; to the &lt;code&gt;Cargo.toml&lt;/code&gt; file, and&lt;/li&gt;
&lt;li&gt;add &lt;code&gt;crate-type = ["cdylib"]&lt;/code&gt; in that new section.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This tells Rust that it will be compiling a shared library appropriate to the OS we build it on. Since we're on Windows, it'll be generating &lt;code&gt;.dll&lt;/code&gt; files.&lt;/p&gt;
&lt;p&gt;And with that, let's put some Rust code in our &lt;code&gt;lib.rs&lt;/code&gt;!&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-rust"&gt;// Tell Rust that we want our ABI to be C flavoured:
#[repr(C)]

// Create the equivalent of a Vec3:
pub struct Orientation {
  pitch: f64,
  roll: f64,
  yaw: f64,
}

// Give that struct an .add() function:
impl Orientation {
  fn add(&amp;amp;mut self, pitch: f64, roll: f64, yaw:f64) -&amp;gt; &amp;amp;mut Orientation {
    self.pitch += pitch;
    self.roll += roll;
    self.yaw += yaw;
    return self;
  }
}

// And then let's write a function that takes an Orientation as input,
// does "something", and then returns that Orietation as output:
#[no_mangle]
pub extern fn orientation_test(s: &amp;amp;mut Orientation) -&amp;gt; &amp;amp;mut Orientation {
  return s.add(1.0, 2.0, 3.0);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you're familiar with Rust none of this should be too surprising, but you might notice the &lt;code&gt;#[repr(C)]&lt;/code&gt;, which tells Rust that we want the library's &lt;a href="https://en.wikipedia.org/wiki/Application_binary_interface"&gt;application binary interface&lt;/a&gt; to conform to the C version, because Node only knows how to work with C flavoured ABIs. You might also notice the &lt;code&gt;#[no_mangle]&lt;/code&gt; which is &lt;em&gt;super&lt;/em&gt; important: by default Rust will optimize function names, which is convenient for generating smaller executables but is &lt;em&gt;disastrous&lt;/em&gt; for libraries, where the point is that we want to call functions that we export &lt;em&gt;using the name we gave them&lt;/em&gt;. So we tell Rust not to mangle the function name.&lt;/p&gt;
&lt;p&gt;And that's it, we can now run &lt;code&gt;cargo build&lt;/code&gt; and it'll generate us a &lt;code&gt;target/debug/testlib.dll&lt;/code&gt; file to use in "whatever knows how to import DLL files"!&lt;/p&gt;
&lt;p&gt;So let's move on to Node. We're first going to initialize the Rust project as a Node project, too, using &lt;code&gt;npm init&lt;/code&gt;, after which we need to install something that'll let us work with DLL files, i.e. we want an &lt;a href="https://en.wikipedia.org/wiki/Foreign_function_interface"&gt;FFI&lt;/a&gt; solution, and the one we'll be using is &lt;a href="https://koffi.dev/"&gt;koffi&lt;/a&gt;: &lt;code&gt;npm install koffi&lt;/code&gt; and we're good to go.&lt;/p&gt;
&lt;p&gt;Let's create a &lt;code&gt;test.js&lt;/code&gt; and make it use our DLL file!&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-js"&gt;// First we import koffi and load our library, using the extension appropriate to our OS.
// Remember, just because we're on Windows doesn't mean we should be LOCKED into Windows!
import koffi from "koffi";
const { platform } = process;
const libraryPath = `./target/debug/testlib.${
  platform === `win32` ? `dll` : `so`
}`;
const lib = koffi.load(libraryPath);

// Then we'll need a JS-equivalent of the struct our library uses:
const Orientation = koffi.struct(`Orientation`, {
  pitch: `double`,
  roll: `double`,
  yaw: `double`,
});

// And of course, we need a function handle, which requires specifying the function name we
// want from the library, as well as what output it generates, given which inputs:
const orientationTest = lib.func(`orientation_test`, Orientation, [Orientation]);

// And with that we're ready to run some native code!
const data = { pitch: 0, roll: 0, yaw: 0 };
let result = data;
const start = performance.now();
for(let i=0; i&amp;lt;10000; i++) result = orientationTest(result);
console.log(`test result:`, result, `- 10,000 iterations took ${(performance.now() - start)|0}ms`);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we now run this using &lt;code&gt;node test.js&lt;/code&gt; we see:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;test result: { pitch: 10000, roll: 20000, yaw: 30000 } - 10,000 iterations took 13ms
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;How cool is that? We're no longer stuck with running code at the speed of JS, we can run code at &lt;em&gt;native&lt;/em&gt; speed by handing the number-crunchy, resource -intensive parts over to Rust, while keeping the convenient of JS for all the other parts of our code. It's the best of both worlds!&lt;/p&gt;
</description>

<link>http://pomax.github.io/#gh-weblog-1691255244859</link>
<guid>http://pomax.github.io/#gh-weblog-1691255244859</guid>
<pubDate>Sat, 05 Aug 2023 17:07:24 GMT</pubDate>
</item>
<item>
<title> Generating a 3D LUT with Photoshop for OBS/Atomos/etc.</title>
<description>&lt;p&gt;Have you ever needed a 3D cube LUT? Turns out, all you need is Photoshop! Whip out Photoshop and create a bunch of "adjustment layers" for your colour correction...&lt;/p&gt;
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/177243/235992202-f9203283-9437-4c28-95f8-70555804c527.png" alt="image"&gt;&lt;/p&gt;
&lt;p&gt;And then export that to a LUT using "export" -&amp;gt; "Color Lookup Tables..." with only "CUBE" as format and 32 points. Brilliant: instant 33 point 3d LUT for use in OBS, your video monitor,  in-camera, through a LUT box, etc. etc.!&lt;/p&gt;
&lt;p&gt;But then you load it into OBS, or your LUT box, and oh no your video feed suddenly looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/177243/234699746-5c492161-e373-4e57-b4fb-a43c7a7c4d42.png" alt="{C9DE6C3A-EC6B-492A-A830-9B29F1A70590}"&gt;&lt;/p&gt;
&lt;p&gt;The problem you're seeing is almost certainly caused by having multiple image layers under your adjustment layer(s):&lt;/p&gt;
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/177243/234700423-866d74a7-a68a-4c0a-a81d-feea987a42f3.png" alt="image"&gt;&lt;/p&gt;
&lt;p&gt;And the solution is to just flatten all of those, &lt;em&gt;then&lt;/em&gt; export your color adjustments as a cube LUT:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/177243/234700619-56851d7d-04f1-4cf4-96a1-6f84dafaac39.png" alt="image"&gt;&lt;/p&gt;
&lt;p&gt;And presto, suddenly your LUT works just fine in OBS, or your LUT box, or any other context that needs a cube LUT:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/177243/234700798-76327d7a-fa6c-4388-bacc-b4e837789a34.png" alt="image"&gt;&lt;/p&gt;
</description>
<category>3D</category>
<category>cube</category>
<category>lut</category>
<category>photoshop</category>
<category>obs</category>
<link>http://pomax.github.io/#gh-weblog-1682542272279</link>
<guid>http://pomax.github.io/#gh-weblog-1682542272279</guid>
<pubDate>Wed, 26 Apr 2023 20:51:12 GMT</pubDate>
</item>
<item>
<title>Leaving twitter</title>
<description>&lt;p&gt;In October of 2022, Elon Musk, a man who failed up harder than anyone else in history, decided to buy Twitter with the express intent to turn it into a completely different product. He laid off thousands of people, devalued the company by 50%, and started pushing through changes that not only changed the experience of the platform, but also made sure that you had no way of actually seeing the content you wanted, while at the same time pushing ads into every single stream presented to you.&lt;/p&gt;
&lt;p&gt;I signed up for Twitter back in 2009, and it's fun a (mostly) fun ride, but even when it wasn't, there were always two things preventing folks from leaving the platform: (1) it was rarely &lt;em&gt;that&lt;/em&gt; bad, and (2) there was no genuine alternative. &lt;/p&gt;
&lt;p&gt;Both those things changed in recent years. For several years now, Mastodon has been an alternative to Twitter, and with Elon's destruction of Twitter the number of both Mastodon users and Mastodon servers has exploded. It's now a perfectly fine alternative with plenty of folks to follow. No, they're not all on the same server, but it's not like you had problems sending emails to people who didn't use your email server before, and this is the same. Just follow them, irrespective of which server they happen to use. Done, you just need to know their "homepage", hardly a chore.&lt;/p&gt;
&lt;p&gt;So as Musk lands more and garbage features in a desperate attempt to short-term claw back money, I'm calling it quits. To prevent people from namesquatting, I'm keeping my twitter account, and I'm not deleting any old tweets, but I'll be using mastodon exclusively from now on. &lt;/p&gt;
&lt;p&gt;Find me over on &lt;a href="https://mastodon.social/@TheRealPomax"&gt;https://mastodon.social/@TheRealPomax&lt;/a&gt;&lt;/p&gt;
</description>
<category>Mastodon</category>
<category>Twitter</category>
<link>http://pomax.github.io/#gh-weblog-1681585670331</link>
<guid>http://pomax.github.io/#gh-weblog-1681585670331</guid>
<pubDate>Sat, 15 Apr 2023 19:07:50 GMT</pubDate>
</item>
<item>
<title> Getting elevation data out of DEM/DSM GeoTIFF files</title>
<description>&lt;p&gt;I'm working on a fun little side project implementing an autopilot in JavaScript to "drive" planes in Microsoft Flight Simulator 2020, and one of the things it needs is an altitude computer/terrain follow system. And in order to make that reasonably accurate, I figured I'd download the entire planet's elevation data in the form of the &lt;a href="https://www.eorc.jaxa.jp/ALOS/en/dataset/aw3d30/aw3d30_e.htm"&gt;ALOS Wolrd 3D (30m)&lt;/a&gt; dataset. This is around 450GB of DSM data, and takes the form of &lt;a href="http://geotiff.maptools.org/spec/geotiff2.html"&gt;GeoTiff&lt;/a&gt; files.&lt;/p&gt;
&lt;p&gt;Conventional GIS wisdom says that in order to work with that, you need to use &lt;a href="https://gdal.org/"&gt;GDAL&lt;/a&gt;, which has no Node bindings, but it has a Python API. And Python's not hard to use, but having to use two different programming languages is inconvenient. So after writing working python GDAL code, which takes 23 seconds to get the full file list of available tiles on my NAS, I figured I'd see if there was a Node library that worked with GDAL anyway.&lt;/p&gt;
&lt;p&gt;Turns out there is, or rather, there are. I ended up using &lt;a href="https://github.com/mmomtchev/node-gdal-async"&gt;gdal-async&lt;/a&gt;, which is a fork of &lt;a href="https://github.com/contra/node-gdal-next"&gt;https://github.com/contra/node-gdal-next&lt;/a&gt;, which is a fork of &lt;a href="https://github.com/naturalatlas/node-gdal"&gt;https://github.com/naturalatlas/node-gdal&lt;/a&gt;,  and reimplementing the logic on the Python side in Node yields a codebase that can index the same files, on the same NAS, in 7 seconds instead of 23. So that's weird, but better than before.&lt;/p&gt;
&lt;p&gt;I ended up writing out the file index to a 24000 line JSON file as a cache, hoping that'd be faster, and where it takes Python a bit to run through that, Node.js loads that instantly. &lt;em&gt;And&lt;/em&gt; parses it to a JS datastructure. The server's just up the moment I run &lt;code&gt;node server.js&lt;/code&gt; instead of spending a second or two starting up. &lt;/p&gt;
&lt;p&gt;But it gets better: why am I using GDAL at all if all I want is the elevations for GPS coordinates? Surely, GeoTIFF is not so complex that only giant GIS projects can make sense of them? And it turns out that, no, it's not. It's in fact near-trivial to write your own code for this provided you know a little bit of programming: GeoTIFF put all the information you need in the "fields" section of an IFD block (the kind of blocks a TIFF file is built up from), so we can just use &lt;a href="https://www.npmjs.com/package/tiff"&gt;a tiff parser&lt;/a&gt; to get those fields, and then look up what values we need in order to map GPS coordinates to TIFF pixel indices (See &lt;a href="https://stackoverflow.com/a/75647596/740553"&gt;https://stackoverflow.com/a/75647596/740553&lt;/a&gt; for an overly detailed explanation on the how!)&lt;/p&gt;
&lt;p&gt;So, how much code is it when we implement the entire thing, bar the TIFF parser, ourselves? This much code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="lang-javascript"&gt;import { existsSync, copyFileSync, readFileSync, writeFileSync } from "fs";
import { basename, join } from "path";
import tiff from "tiff";
const { floor, ceil } = Math;

const __dirname = url.fileURLToPath(new URL(".", import.meta.url));
const INDEX_FILE = join(__dirname, `alos-index.json`);
const CACHE_DIR = join(__dirname, `cache`);
const ALOS_VOID_VALUE = -9999;

class ALOSTile {
  constructor(tilePath) {
    this.tilePath = tilePath;
    // copy to cache dir for faster loading
    const filename = join(`.`, CACHE_DIR, basename(tilePath));
    if (!existsSync(filename)) copyFileSync(tilePath, filename);
    this.init(filename);
  }

  init(filename) {
    const file = readFileSync(filename);
    const image = tiff.decode(file.buffer);
    const block = (this.block = image[0]);
    const fields = block.fields;
    let [sx, sy, sz] = fields.get(33550);
    let [px, py, k, gx, gy, gz] = fields.get(33922);
    sy = -sy;
    this.reverse = [-gx / sx, 1 / sx, 0, -gy / sy, 0, 1 / sy];
    this.pixels = block.data;
  }

  lookup(lat, long) {
    const { reverse: T, block } = this;
    const x = T[0] + T[1] * long + T[2] * lat;
    const y = T[3] + T[4] * long + T[5] * lat;
    const pos = (x | 0) + (y | 0) * block.width;
    const value = this.pixels[pos];
    return value ?? ALOS_VOID_VALUE;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There, that's the entire code &lt;em&gt;plus convenience wrapper&lt;/em&gt; to do an elevation lookup in a GeoTIFF tile. No GDAL, no Python, heck we don't even need to care about which programming language we're using as long as it has a TIFF parser it can use. The rest is just absolutely basic programming.&lt;/p&gt;
</description>
<category>Node</category>
<category>GIS</category>
<category>GDAL</category>
<category>MSFS</category>
<category>MSFS 2020</category>
<category>Elevation</category>
<category>DEM</category>
<category>DSM</category>
<link>http://pomax.github.io/#gh-weblog-1678206967957</link>
<guid>http://pomax.github.io/#gh-weblog-1678206967957</guid>
<pubDate>Tue, 07 Mar 2023 16:36:07 GMT</pubDate>
</item>
<item>
<title>MacOS and external SSDs</title>
<description>&lt;p&gt;Ever had your external SSD refuse to remount when you plug it into MacOS because it's an idiotic OS and remembers you didn't properly ejected it?&lt;/p&gt;
&lt;p&gt;First, kill &lt;code&gt;fsck&lt;/code&gt; (the "file system consistency check" with the dumbest command name) because it's ruining the party right now:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ps aux | grep fsck
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Find the process id and &lt;code&gt;sudo kill -9 thatid&lt;/code&gt; because goddamnit, fsck, stop ruining the party. It's even going to do a fake out, because there's probably two pids, and only one of them is real. The other's a zombie process.&lt;/p&gt;
&lt;p&gt;With the main one killed, we can remount the drive:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ diskutils mount /Volumes/disk3s2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or whatever your disk volume is according to Disk Utility.&lt;/p&gt;
</description>
<category>MacOS</category>
<category>SSD</category>
<category>fsck</category>
<link>http://pomax.github.io/#gh-weblog-1676434414432</link>
<guid>http://pomax.github.io/#gh-weblog-1676434414432</guid>
<pubDate>Wed, 15 Feb 2023 04:13:34 GMT</pubDate>
</item>
<item>
<title> Adding a physical drive to a VMware Workstation VM</title>
<description>&lt;p&gt;If VMWare complains that it has insufficient rights to use a physical drive with adding a hard disk in the VM settings: open computer management with admin rights, then look for that drive in the list. If it has a drive letter: remove the drive letter. &lt;/p&gt;
&lt;p&gt;Remember: adding a physical drive means literally giving it to the guest OS, not "sharing it between the host and the guest", so remove its drive letter in computer management to &lt;em&gt;guarantee&lt;/em&gt; that your host's Windows can't use it. Once done, you can add it to your VM without any problems.&lt;/p&gt;
&lt;p&gt;And if you need to &lt;em&gt;share&lt;/em&gt; drives, just use network sharing. That's what it's for.&lt;/p&gt;
</description>
<category>VMware</category>
<category>Workstation</category>
<category>drive</category>
<category>errors</category>
<link>http://pomax.github.io/#gh-weblog-1672175588471</link>
<guid>http://pomax.github.io/#gh-weblog-1672175588471</guid>
<pubDate>Tue, 27 Dec 2022 21:13:08 GMT</pubDate>
</item>
<item>
<title> Structs in Python</title>
<description>&lt;p&gt;Python does not have syntax for writing C structs, or things that act like them, but thankfully you can write a class decorator that adds something that feels like it should have been in the language from day one.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import copy


def struct(struct_class):
    # extract the struct members
    member_names = []
    member_values = []
    for attr_name in dir(struct_class):
        if not attr_name.startswith('_'):
            value = getattr(struct_class, attr_name)
            if not callable(value):
                member_names.append(attr_name)
                member_values.append(value)

    # create a new init
    def struct_init(self, *args, **kwargs):
        i = 0  # we really don't need enumerate() here...
        for value in args:
            name = member_names[i]
            default_value = member_values[i]
            setattr(self, name, value if value is not None else default_value)
            i += 1  # ...we just need to inc an int
        for key, value in kwargs.items():
            if key in member_names:
                i = member_names.index(key)
                default_value = member_values[i]
                setattr(self, key, value if value is not None else default_value)
        # fall through  to the struct constructor.
        if hasattr(self.__class__, 'constructor'):
            self.constructor(**kwargs)

    # A struct can be iterated over, yielding and ordered list
    # based on member names defined in the struct class.
    def member_iter(self):
        return [copy.deepcopy(getattr(self, name)) for name in member_names].__iter__()

    # Structs do not allow shallow copying. All copies are a deep copies.
    def deep_copy(self):
        return copy.deepcopy(self)

    # rebind and return
    struct_class.__init__ = struct_init
    struct_class.__iter__ = member_iter
    struct_class.__copy__ = deep_copy
    return struct_class
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this, we can write code with nice Struct-likes:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from as_struct import struct

@struct
class Orientation():
    pitch = 0
    roll = 0
    yaw = 0

@struct
class Trim():
    elevator = 0
    aileron = 0
    rudder = 0

class Brrrrrr():
    def __init__(self):
        self.description = "I'm a plane!"
        self.orientation = Orientation()
        self.trim = Trim()

    def trim(self, e=0, a=0, r=0):
        self.trim.elevator += e
        self.trim.aileron += a
        self.trim.rudder += r
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Done.&lt;/p&gt;
</description>
<category>Python</category>
<category>struct</category>
<category>decorator</category>
<link>http://pomax.github.io/#gh-weblog-1671995243640</link>
<guid>http://pomax.github.io/#gh-weblog-1671995243640</guid>
<pubDate>Sun, 25 Dec 2022 19:07:23 GMT</pubDate>
</item>
<item>
<title> React is just JavaScript</title>
<description>&lt;p&gt;React has had a fairly profound effect on the web, whether you like React or not, and whether you like the effect it had or not. However, the one thing it's done that's somewhat puzzling is make people think that React is its own thing, rather than just JS. Things that are trivial become colossal tasks and implementations because folks try to do them "in React". Anything that isn't DOM-update related needs a React solution, instead of using the JS APIs that are right there for you to use. So let's talk about a few.&lt;/p&gt;
&lt;h2 id="how-do-i-tell-component-x-about-an-update-in-component-y-"&gt;How do I tell component X about an update in component Y?&lt;/h2&gt;
&lt;p&gt;Imagine this: you wrote a React app that has a status and a whole bunch of different content, and you need to make sure your status bar reflects whatever is active right now. So you add a ref to your status bar, communicate that up to the parent &lt;code&gt;App&lt;/code&gt;, which can then pass down a handler to every component until it makes it down into your components that can be active.&lt;/p&gt;
&lt;p&gt;Or, you go "oh right, wait, I'm in a browser" and you just use events: your active component just fires-and-forgets a &lt;code&gt;document.dispatchEvent(new CustomEvent(`status:active`, { detail: ... }))&lt;/code&gt; and your status bar registers a listener for that event when it mounts. We are done: nothing needs to run up and down an entire virtual DOM tree. And because this is basically just utility functionality, we write it as its own function that any component that needs to update the status bar can use, which we can import &lt;em&gt;from&lt;/em&gt; the Status bar:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// The only code that cares about this event name is the code
// in this file, so we capture it as a constant and nothing will
// ever need to care about what it is.
const STATUS_EVENT_NAME = `app:status:update`;

// yes, this is when you want a class, not a functional component
export class StatusBar extends React.Component {
  static getDefaultState() {
    return { statusMessage: `` };
  }
  constructor(props) {
    super(props);
    this.state = StatusBar.getDefaultState();
  }
  reset() {
    this.setState(StatusBar.getDefaultState());
  }
  componentDidMount() {
    document.addEventListener(STATUS_EVENT_NAME, evt =&amp;gt; {
      const { statusMessage } = evt.detail;
      this.setState({ statusMessage });
    );
  }
  render() {
    return &amp;lt;footer className=""&amp;gt;{ this.state.statusMessage }&amp;lt;/footer&amp;gt;
  }
}

// And a nice function that other components with a status bar text can import and use:
export function updateStatusBar(msg) {
  const evt = new CustomEvent(STATUS_EVENT_NAME, { detail: msg });
  document.dispatchEvent(evt);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And look at that: no refs, no property forwards, or even crazier "sending the handler up to the parent once it's available" nonsense. You want some content to update the status bar? Just do that:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import { updateStatusBar } from "./StatusBar.js";

export const SomeContent = function(props) {
  useEffect(() =&amp;gt; updateStatusBar(props.toolTip), props.toolTip);
  return &amp;lt;......&amp;gt;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Heck, this even works when there is no status bar component on the page. The events just get thrown away if there are no listeners for it, and everything works perfectly fine.&lt;/p&gt;
&lt;h2 id="how-do-i-synchronize-data-across-components-"&gt;How do I synchronize data across components?&lt;/h2&gt;
&lt;p&gt;Well, you could use Redux and learn a complex new technology, or you could just use JS, because anything running client-side is running within the same context, and imports are cached, so imports are shared by default. Want to see something that looks like it shouldn't be this simple?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export const dataPool = {};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Boom, done. Anything with &lt;code&gt;import { dataPool } from "datapool.js";&lt;/code&gt; will now be sharing the same object. It's how JS works by design, we get this for free. And you can even get fancy without bolting on a data syncing framework until you absolutely need it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const pool = {};
export const dataPool = {
  register: listener =&amp;gt; listeners.push(listener);
  unregister: listener =&amp;gt; {
    const pos = listeners.indexOf(listener);
    if (pos &amp;gt; -1) listeners.splice(pos, 1);
  },
  getValue: (name) =&amp;gt; pool[name],
  setValue: (name, value) =&amp;gt; {
    pool.name = value;
    for (let listener of listeners) listener.poolUpdated?(name, value);
  }
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And now you have a synced data pool that uses a pub/sub model for data updates in less than 15 lines of code. &lt;/p&gt;
&lt;h3 id="but-this-doesn-t-persist-"&gt;But this doesn't persist!&lt;/h3&gt;
&lt;p&gt;So save the data to &lt;code&gt;localStorage&lt;/code&gt;, that's what it's for:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const dataKey = `app:dataPool`;
const pool = JSON.parse(localStorage.getItem(dataKey) ?? `{}`);

export const dataPool = {
  register: listener =&amp;gt; listeners.push(listener);
  unregister: listener =&amp;gt; {
    const pos = listeners.indexOf(listener);
    if (pos &amp;gt; -1) listeners.splice(pos, 1);
  },
  getValue: (name) =&amp;gt; pool[name],
  setValue: (name, value) =&amp;gt; {
    pool.name = value;
    localStorage.setItem(dataKey, JSON.stringify(pool));
    for (let listener of listeners) listener.poolUpdated?(name, value);
  }
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Done. And now you have an excellent signal for when it's time to start thinking about more complex solutions, because &lt;code&gt;localStorage&lt;/code&gt; has limited space available. If you're syncing more than a few MB across lots of components, it's probably time to rethink your app architecture.&lt;/p&gt;
&lt;h2 id="i-want-to-close-my-modal-component-when-someone-clicks-or-taps-outside-of-it"&gt;I want to close my modal component when someone clicks or taps outside of it&lt;/h2&gt;
&lt;p&gt;This one's close to my heart because I originally wrote react-onclickoutside almost a decade ago now because back in Þe olden times JS was missing a &lt;em&gt;ton&lt;/em&gt; of features that modern JS has. Time has moved on, JS got updated a lot since, and so in modern JS we just.... don't need it anymore. Instead you can make this work with just a few lines of JS:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import { setupOutsideClickListener } from "./somewhere";

export const Menu = (props) =&amp;gt; {
  const menuRef = useRef(null);

  // let's assume we're smart and have a const function for toggling
  // visibility of this component, used by whatever other logic needs
  // to control visibility
  const toggle = () =&amp;gt; { ... }

  // set up the event listeners, using `[]` as dependency list so it only runs once.
  useEffect(() =&amp;gt; setupOutsideClickListener(menuRef, toggle), []);

  return (
    &amp;lt;dialog ref={menuRef} ... &amp;gt;
      &amp;lt;span className="close-icon" onClick={toggle}&amp;gt;X&amp;lt;/span&amp;gt;
        ...
    &amp;lt;/dialog
  );
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And here's our plain JavaScript:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export function setupOutsideClickListener(owner, toggle) {
  // always remember that if you have "click" handling, you better have a "touchstart", too!
  for (let type of [`click`, `touchstart`]) {
     document.addEventListener(type, ({ target }) =&amp;gt; {
        // if this dialog is not on the page, or the events occur anywhere inside our dialog, we ignore the events.
        if (owner.current?.contains(target)) return;
        // if the dialog is on the page and the events are outside of it, toggle its visibility.
        toggle();
      });
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="and-so-much-more"&gt;And so much more&lt;/h2&gt;
&lt;p&gt;Unless you're already a seasoned programmer, you're almost certainly writing way too much code to do what you need, simply because you've been focusing on React too much, and not spending some time with plain JS to understand what this language that you're using can actually do. Once you've spent some time with React, the best thing you can do for yourself is putting React down, and reading up on modern JS on the web - what it can do, what syntax it uses for that, and how a lot of that can replace what you've used &lt;em&gt;a lot&lt;/em&gt; of code for with surprisingly little code.&lt;/p&gt;
&lt;p&gt;Should you never use Redux? Or HoCs? Or anything else that's complex but full featured and everyone seems to be using? No of course not, but you should know &lt;em&gt;why&lt;/em&gt; you're using them, because they solve specific problems, and those are almost certainly not your problems. &lt;em&gt;Yet&lt;/em&gt;&lt;/p&gt;
</description>
<category>React</category>
<category>JavaScript</category>
<link>http://pomax.github.io/#gh-weblog-1657467300033</link>
<guid>http://pomax.github.io/#gh-weblog-1657467300033</guid>
<pubDate>Sun, 10 Jul 2022 15:35:00 GMT</pubDate>
</item>
<item>
<title> Cleaning up your Django migrations</title>
<description>&lt;p&gt;We use &lt;a href="https://wagtail.org/"&gt;Wagtail&lt;/a&gt;, a Django-based CMS, at the Mozilla Foundation to host &lt;a href="https://foundation.mozilla.org"&gt;https://foundation.mozilla.org&lt;/a&gt;, as well as &lt;a href="http://donate.mozilla.org"&gt;http://donate.mozilla.org&lt;/a&gt;, and as nice as Django is, it is pretty terrible at migration and app management. The official stance is "you shouldn't worry about how many migrations you have", and for a base Django installation, that might very well be true.&lt;/p&gt;
&lt;p&gt;For Wagtail installations, it very much isn't. Thanks to Wagtail's &lt;a href="https://docs.wagtail.org/en/stable/topics/streamfield.html"&gt;streamfield&lt;/a&gt; concept, which models free-form page body content "out of band" (using a single huge JSON string for each stream, rather than linked table data) you can end up with migrations where your code change may have been a short string update, but the migration for that updates the &lt;em&gt;entire&lt;/em&gt; streamfield definition JSON. A four letter change in your code can easily lead to a 12kb change in a migration field. Times every model that uses that same streamfield definition. 50kb+ migrations for tiny code changes are not unusual.&lt;/p&gt;
&lt;p&gt;So, when you use Wagtail you will almost certain run into the need to squash your migrations much sooner than you ever would if you just used plain Django, and we've had to do this enough times that it's really worth just writing down how to properly do this. So here's a checklist for you to run through:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use &lt;code&gt;squashmigration&lt;/code&gt; to first extremely-poorly-consolidate all your wagtail app's migrations: &lt;code&gt;python manage.py squashmigrations yourappname 1234&lt;/code&gt; (where 1234 is your most recent migration number). This will create a new &lt;code&gt;0001&lt;/code&gt; migration that is almost certainly not going to work without further editing because squashing does not automatically copy over any of your "run this during a migration" code. So we'll need to create a new migration file for that:&lt;/li&gt;
&lt;li&gt;Create a new migration file 0002 with a dependency on the new 0001, exclusively for data bootstrapping. Note that you do &lt;em&gt;not&lt;/em&gt; need any of the code that migrated data "between migrations": when squashing your migrations, all your model definitions and data are already up to date with respect to your current code, meaning that none of the migration functions that you had to run in the past to uplift older data to a newer form is relevant anymore. However, migration functions that &lt;em&gt;create&lt;/em&gt; data should all be put in your new 0002 migration. With, of course, the code updated to do what it's supposed to do given your &lt;em&gt;current&lt;/em&gt; code.  And of course, remember to remove all the &lt;code&gt;runPython&lt;/code&gt; instructions from the new 0001 migration&lt;/li&gt;
&lt;li&gt;After testing (of course), push these changes all the way through to production. &lt;/li&gt;
&lt;li&gt;We can now remove the old migrations: delete everything except the new 0001 and 0002, and make sure to update 0001 so that it no longer claims that it &lt;code&gt;replaces = ...&lt;/code&gt;, as those migration files will no longer exist.&lt;/li&gt;
&lt;li&gt;After testing (of course), again push these changes all the way through to production. &lt;/li&gt;
&lt;li&gt;We can now perform the part that we wanted from the start: move the newly created &lt;code&gt;0001&lt;/code&gt; and &lt;code&gt;0002&lt;/code&gt; migration files to a temp dir so that the &lt;code&gt;migrations&lt;/code&gt; dir is empty, and run &lt;code&gt;python manage.py makemigrations&lt;/code&gt; to create &lt;em&gt;completely new, fresh, clean, model definitions&lt;/em&gt;. Django is pretty terrible at migration optimization (which isn't its fault: that's a hard problem), and this step basically goes "okay, we know the model definitions are a single migration, so a completely new migration will lead to the same model definitions getting set up". Except without needing to optimize anything: you're quite likely to end up with a migration that is 10x smaller than the original squashed migration Django created.&lt;/li&gt;
&lt;li&gt;Make sure this newest 0001 migration has some name that is unique to when you're doing the work. E.g. &lt;code&gt;0001_2022_02_24_reset_models.py&lt;/code&gt;, and copy the original squash migration &lt;code&gt;0001&lt;/code&gt; and data bootstrap &lt;code&gt;0002&lt;/code&gt; that we moved to a temp dir back into the &lt;code&gt;migrations&lt;/code&gt; dir. Update the super clean migration so that it has a &lt;code&gt;replaces = ...&lt;/code&gt;  list, and have that list be the squashed 0001 and data bootstrap 0002 names.&lt;/li&gt;
&lt;li&gt;Copy the 0002 data bootstrap migration as a new 0002 file with the same kind of name as our super clean migration, e.g. &lt;code&gt;0002_2022_02_24_reset_data_bootstrap.py&lt;/code&gt; and update its &lt;code&gt;dependencies&lt;/code&gt; field to point to &lt;code&gt;0001_2022_02_24_reset_models&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;After testing (of course), we push these changes all the way through to production for a third time. We are not done yet.&lt;/li&gt;
&lt;li&gt;We can now delete the original squash migration and its data bootstrap migration, and remove the &lt;code&gt;replaces&lt;/code&gt; field from our super clean 0001 migration.&lt;/li&gt;
&lt;li&gt;After testing (yet again), we push these changes all the way through to production for the last time.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Congratulations, you probably just cut your &lt;code&gt;python manage.py migrate&lt;/code&gt; runtime in half, if not more. &lt;/p&gt;
&lt;p&gt;But we're not done, because Django doesn't actually &lt;em&gt;know&lt;/em&gt; what we've done: its migration table still contains all the old migration information despite those files no longer existing, so we're going to have to go into the DB and update that part, too.  First off, connect to your production database, and run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT FROM django_migrations WHERE app = 'your_app_name';
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will show you all the migrations the django has ever see for your app. All but two of those are completely irrelevant now, so we're going to remove them. Take note of the &lt;code&gt;id&lt;/code&gt; for the new clean migration and its data bootstrap migration, and then run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; DELETE FROM django_migrations WHERE app = 'your_app_name' AND id &amp;lt; 1234567;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Where that &lt;code&gt;1234567&lt;/code&gt; is the lower of the two id numbers for your clean migrations.&lt;/p&gt;
&lt;p&gt;However, remember to &lt;strong&gt;always have database backups&lt;/strong&gt; before you do something like this. &lt;/p&gt;
&lt;p&gt;Also note, that this &lt;strong&gt;will cause problems&lt;/strong&gt; if you have multiple apps that have migration cross dependencies to your just-cleaned-up app. You will need to run this clean-squash procedure for &lt;em&gt;every&lt;/em&gt; app with dependencies on any of the apps you're cleaning this way, before you can clean up the &lt;code&gt;django_migrations&lt;/code&gt; table.&lt;/p&gt;
&lt;p&gt;And yeah: it's absolutely crazy that Django's been around for over fifteen years, but no one's really bothered to actually make this part easy. And don't even get me started on renaming a Django app. Heaven forbid you'd ever want to do that.&lt;/p&gt;
</description>

<link>http://pomax.github.io/#gh-weblog-1645994687853</link>
<guid>http://pomax.github.io/#gh-weblog-1645994687853</guid>
<pubDate>Sun, 27 Feb 2022 20:44:47 GMT</pubDate>
</item>
<item>
<title> Setting up "lots of HTTPS servers" with Node </title>
<description>&lt;p&gt;I'm working on a &lt;code&gt;server&lt;/code&gt; ⇆ &lt;code&gt;client&lt;/code&gt; ⇆ &lt;code&gt;browser-as-thin-client&lt;/code&gt; project where there is a single server, running an HTTPS and WS server process, with clients that first connect to the web server "Front door" before being sent on to their own dedicated websocket URL. These clients are just "computer programs" that someone can attach to with their browser if they need a user interface into the client, and so each client also runs their own little websocket server to allow for that.&lt;/p&gt;
&lt;p&gt;At some point, the idea is of course that the server runs on one machine, and clients run on however-many secondary machines, but for testing purposes that makes no sense: the server and clients all run on the same hardware.&lt;/p&gt;
&lt;p&gt;Which means I needed to set up HTTPs/SSL in a way that works for all these things, and thankfully it turns out that Node.js allows you to do this pretty easily. It even has &lt;a href="https://nodejs.org/api/https.html#httpscreateserveroptions-requestlistener"&gt;example code for this&lt;/a&gt; on the API pages for the &lt;code&gt;https&lt;/code&gt; module, which can be used in combination with a Let's Encrypt &lt;a href=""&gt;certbot&lt;/a&gt; key and certificate, and some env vars to regulate whether to use https or not:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import http from "http";
import https from "https";

const { USE_HTTPS, DOMAIN_NAME, PORT } = process.env;
const useHTTPS = USE_HTTPS === `true`;
const protocol = useHTTPS ? `https` : `http`;
const domain = DOMAIN_NAME || `localhost`;
const port = parseInt(PORT) || 8000;

const httpsOptions = {};

if (useHTTPS) {
  const certDir = `/etc/letsencrypt/live`;
  httpsOptions.key = fs.readFileSync(`${certDir}/${domain}/privkey.pem`);
  httpsOptions.cert = fs.readFileSync(`${certDir}/${domain}/fullchain.pem`);
}

function routHandlers(request, response) { 
  // ...
}

const namespace = (useHTTPS ? https : http);
const server = namespace.createServer(useHTTPS ? httpsOptions : undefined, routHandlers);

server.listen(port, () =&amp;gt; {
  console.log(`Server is listening on ${protocl}//${domain}:${port}`);
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then you just make sure every single server uses this approach.&lt;/p&gt;
</description>
<category>Node</category>
<category>HTTPS</category>
<category>server</category>
<link>http://pomax.github.io/#gh-weblog-1638815860591</link>
<guid>http://pomax.github.io/#gh-weblog-1638815860591</guid>
<pubDate>Mon, 06 Dec 2021 18:37:40 GMT</pubDate>
</item></channel>
</rss>
